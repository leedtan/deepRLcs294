3.6.0 |Anaconda custom (64-bit)| (default, Dec 23 2016, 12:22:00) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]
loading and building expert policy
obs (1, 376) (1, 376)
loaded and built
iter 0
iter 1
iter 2
iter 3
iter 4
iter 5
iter 6
iter 7
iter 8
iter 9
iter 10
iter 11
iter 12
iter 13
iter 14
iter 15
iter 16
iter 17
iter 18
iter 19
returns [141.24046571556036, 140.84143608735241, 119.6649257599384, 144.0146918262958, 138.90563152387477, 146.81989567909315, 222.12779677958952, 126.57592577304591, 121.14453253348628, 140.86732620241889, 187.97718887589076, 123.99189316592191, 137.75438280521476, 124.85022144934993, 149.10903807137655, 130.6938620220846, 151.31831174405499, 113.44885966939043, 129.83584730196964, 130.94564963718915]
mean return 141.106394131
std of return 24.2044767573
learning rate: 0.0707106781187
Epoch:  1  avg train loss: 4.07614424576  Reg Loss: 1.36763203784e-07 total time: 1.4459729194641113
avg loss validation: 0.95810167074 failed count: 0
learning rate: 0.057735026919
Epoch:  2  avg train loss: 0.754752097621  Reg Loss: 2.05173246967e-07 total time: 4.087909460067749
avg loss validation: 0.616593091973 failed count: 0
learning rate: 0.05
Epoch:  3  avg train loss: 0.570023665131  Reg Loss: 2.74410267853e-07 total time: 7.018755674362183
avg loss validation: 0.507003867411 failed count: 0
learning rate: 0.04472135955
Epoch:  4  avg train loss: 0.474913065594  Reg Loss: 3.45273284979e-07 total time: 9.678101539611816
avg loss validation: 0.427171471828 failed count: 0
learning rate: 0.0408248290464
Epoch:  5  avg train loss: 0.417151271264  Reg Loss: 4.12053368917e-07 total time: 12.59140944480896
avg loss validation: 0.376274033545 failed count: 0
learning rate: 0.0377964473009
Epoch:  6  avg train loss: 0.373583391235  Reg Loss: 4.7291397042e-07 total time: 15.218523263931274
avg loss validation: 0.346722015794 failed count: 0
learning rate: 0.0353553390593
Epoch:  7  avg train loss: 0.341970917253  Reg Loss: 5.27884210645e-07 total time: 18.13682246208191
avg loss validation: 0.330018995537 failed count: 0
learning rate: 0.0333333333333
Epoch:  8  avg train loss: 0.319686393018  Reg Loss: 5.79415630413e-07 total time: 21.053074598312378
avg loss validation: 0.296417837876 failed count: 0
learning rate: 0.0316227766017
Epoch:  9  avg train loss: 0.306234886416  Reg Loss: 6.2826458887e-07 total time: 23.74880313873291
avg loss validation: 0.286585609939 failed count: 0
learning rate: 0.0301511344578
Epoch:  10  avg train loss: 0.279412197969  Reg Loss: 6.74348111611e-07 total time: 26.606852769851685
avg loss validation: 0.305029460111 failed count: 1
iter 0
iter 1
iter 2
100/1000
iter 3
100/1000
iter 4
iter 5
100/1000
iter 6
iter 7
iter 8
iter 9
100/1000
iter 10
iter 11
iter 12
100/1000
iter 13
iter 14
iter 15
iter 16
iter 17
iter 18
iter 19
returns [425.99237744087822, 394.13180259903027, 514.77056643309697, 481.3562499862287, 438.89449921116523, 457.63230522082603, 569.23629636715202, 480.70087105100714, 390.88814533943253, 692.97070035024217, 406.63271595614577, 486.12810053591022, 632.48225493981636, 321.97057198971146, 350.63088655436763, 375.26732078557882, 409.12845571886214, 368.0191442458422, 330.32708803199648, 436.6155604394695]
mean return 448.18879566
std of return 94.3158001913
learning rate: 0.0288675134595
Epoch:  11  avg train loss: 0.28833551785  Reg Loss: 7.52128070722e-07 total time: 1.4089462757110596
avg loss validation: 0.286087673891 failed count: 0
learning rate: 0.0277350098113
Epoch:  12  avg train loss: 0.2662148328  Reg Loss: 7.98086151671e-07 total time: 4.345588684082031
avg loss validation: 0.272214428376 failed count: 0
learning rate: 0.0267261241912
Epoch:  13  avg train loss: 0.26188270925  Reg Loss: 8.40670937849e-07 total time: 7.29538106918335
avg loss validation: 0.273205783802 failed count: 1
learning rate: 0.0258198889747
Epoch:  14  avg train loss: 0.250577005002  Reg Loss: 8.82038831546e-07 total time: 8.750378847122192
avg loss validation: 0.244968724825 failed count: 0
learning rate: 0.025
Epoch:  15  avg train loss: 0.236486735676  Reg Loss: 9.20965744237e-07 total time: 11.39820122718811
avg loss validation: 0.248430610055 failed count: 1
learning rate: 0.0242535625036
Epoch:  16  avg train loss: 0.226380592799  Reg Loss: 9.56421967781e-07 total time: 12.856297016143799
avg loss validation: 0.235603048657 failed count: 0
learning rate: 0.0235702260396
Epoch:  17  avg train loss: 0.223193066199  Reg Loss: 9.89338182462e-07 total time: 15.787699222564697
avg loss validation: 0.251835590409 failed count: 1
learning rate: 0.0229415733871
Epoch:  18  avg train loss: 0.214123545769  Reg Loss: 1.02287100484e-06 total time: 17.23698592185974
avg loss validation: 0.261933992349 failed count: 2
learning rate: 0.022360679775
Epoch:  19  avg train loss: 0.214940168434  Reg Loss: 1.05539336801e-06 total time: 18.67995047569275
avg loss validation: 0.214346829165 failed count: 0
learning rate: 0.0218217890236
Epoch:  20  avg train loss: 0.198089236885  Reg Loss: 1.0836411231e-06 total time: 21.363866567611694
avg loss validation: 0.213856278378 failed count: 0
iter 0
100/1000
iter 1
100/1000
iter 2
100/1000
iter 3
100/1000
iter 4
100/1000
iter 5
100/1000
iter 6
100/1000
iter 7
100/1000
iter 8
100/1000
iter 9
iter 10
iter 11
100/1000
iter 12
iter 13
100/1000
200/1000
iter 14
100/1000
iter 15
100/1000
iter 16
100/1000
iter 17
iter 18
100/1000
iter 19
100/1000
returns [1057.8682893541011, 964.30871810922929, 623.81199677983454, 852.61115955693219, 608.22894176656575, 1083.4256103157006, 994.92355174059469, 647.47289056126965, 1200.907030835386, 574.03310123462336, 507.66225565718338, 720.23411922121056, 323.6892807024181, 1357.8366275328071, 794.99994462778056, 658.87025360329619, 726.85911792687421, 562.99385264433113, 1149.6840450622547, 737.52073315666757]
mean return 807.397076019
std of return 260.181368376
learning rate: 0.0213200716356
Epoch:  21  avg train loss: 0.215892956404  Reg Loss: 1.06991277866e-06 total time: 1.4721479415893555
avg loss validation: 0.213203927814 failed count: 0
learning rate: 0.0208514414057
Epoch:  22  avg train loss: 0.204603607902  Reg Loss: 1.0983010714e-06 total time: 4.484124660491943
avg loss validation: 0.199140627588 failed count: 0
learning rate: 0.0204124145232
Epoch:  23  avg train loss: 0.199675219242  Reg Loss: 1.12419957291e-06 total time: 7.497830629348755
avg loss validation: 0.197306345707 failed count: 0
learning rate: 0.02
Epoch:  24  avg train loss: 0.194682649593  Reg Loss: 1.15031927287e-06 total time: 10.225014448165894
avg loss validation: 0.185347431857 failed count: 0
learning rate: 0.0196116135138
Epoch:  25  avg train loss: 0.192935251999  Reg Loss: 1.17404151423e-06 total time: 13.000650882720947
avg loss validation: 0.183327880704 failed count: 0
learning rate: 0.019245008973
Epoch:  26  avg train loss: 0.192798782691  Reg Loss: 1.19706518353e-06 total time: 16.014395475387573
avg loss validation: 0.191319668413 failed count: 1
learning rate: 0.0188982236505
Epoch:  27  avg train loss: 0.180517521259  Reg Loss: 1.22008370248e-06 total time: 17.52282214164734
avg loss validation: 0.197863583208 failed count: 2
learning rate: 0.0185695338177
Epoch:  28  avg train loss: 0.17844374141  Reg Loss: 1.24125198292e-06 total time: 19.03432607650757
avg loss validation: 0.185343033755 failed count: 3
learning rate: 0.0182574185835
Epoch:  29  avg train loss: 0.174685805827  Reg Loss: 1.26067271161e-06 total time: 20.535585403442383
avg loss validation: 0.178204478621 failed count: 0
learning rate: 0.0179605302027
Epoch:  30  avg train loss: 0.175341878164  Reg Loss: 1.28012269435e-06 total time: 23.259113788604736
avg loss validation: 0.168445338148 failed count: 0
iter 0
100/1000
iter 1
100/1000
iter 2
100/1000
iter 3
iter 4
100/1000
iter 5
100/1000
iter 6
iter 7
100/1000
iter 8
100/1000
iter 9
iter 10
100/1000
iter 11
100/1000
iter 12
100/1000
iter 13
100/1000
iter 14
100/1000
iter 15
100/1000
iter 16
100/1000
iter 17
100/1000
iter 18
100/1000
iter 19
100/1000
returns [1188.8365945842145, 707.01984903452751, 862.2884621803646, 639.43659989021046, 919.92056465081646, 621.61409838637883, 521.49258525263804, 866.95150746054242, 805.39068397140807, 441.12323655159565, 994.73711840928092, 773.53774319695663, 781.8133166380818, 829.70113239154603, 976.99127619898684, 640.67261845182304, 704.21529919086413, 1160.2321993636331, 645.54228902504565, 820.74158567277755]
mean return 795.112938025
std of return 187.865792898
learning rate: 0.0176776695297
Epoch:  31  avg train loss: 0.178072722075  Reg Loss: 1.34476415675e-06 total time: 1.5079565048217773
avg loss validation: 0.167572383341 failed count: 0
learning rate: 0.0174077655956
Epoch:  32  avg train loss: 0.172990323425  Reg Loss: 1.36431457761e-06 total time: 4.280330181121826
avg loss validation: 0.175696337113 failed count: 1
learning rate: 0.0171498585143
Epoch:  33  avg train loss: 0.1742354484  Reg Loss: 1.38380540656e-06 total time: 5.827470302581787
avg loss validation: 0.16490607985 failed count: 0
learning rate: 0.0169030850946
Epoch:  34  avg train loss: 0.16708689979  Reg Loss: 1.40334383978e-06 total time: 8.869075059890747
avg loss validation: 0.164219905766 failed count: 0
learning rate: 0.0166666666667
Epoch:  35  avg train loss: 0.159714691655  Reg Loss: 1.4201424007e-06 total time: 11.960836172103882
avg loss validation: 0.171754297663 failed count: 1
learning rate: 0.0164398987305
Epoch:  36  avg train loss: 0.161577675758  Reg Loss: 1.43604710504e-06 total time: 13.523979425430298
avg loss validation: 0.156602551114 failed count: 0
learning rate: 0.0162221421131
Epoch:  37  avg train loss: 0.166956834674  Reg Loss: 1.45253859962e-06 total time: 16.32397723197937
avg loss validation: 0.16063322862 failed count: 1
learning rate: 0.0160128153805
Epoch:  38  avg train loss: 0.154720347023  Reg Loss: 1.46969550039e-06 total time: 17.876265048980713
avg loss validation: 0.173379325457 failed count: 2
learning rate: 0.0158113883008
Epoch:  39  avg train loss: 0.152722118549  Reg Loss: 1.48397976593e-06 total time: 19.4571590423584
avg loss validation: 0.157490549171 failed count: 3
learning rate: 0.0156173761889
Epoch:  40  avg train loss: 0.159411834076  Reg Loss: 1.49824798408e-06 total time: 21.014594554901123
avg loss validation: 0.151314041057 failed count: 0
iter 0
100/1000
iter 1
iter 2
100/1000
200/1000
iter 3
iter 4
100/1000
iter 5
100/1000
iter 6
100/1000
iter 7
iter 8
100/1000
iter 9
100/1000
iter 10
100/1000
iter 11
100/1000
iter 12
100/1000
iter 13
100/1000
iter 14
100/1000
iter 15
100/1000
iter 16
100/1000
iter 17
100/1000
iter 18
100/1000
iter 19
100/1000
returns [902.70812644741216, 629.09944285908625, 1993.0799033656963, 549.05682211499652, 689.64292369847499, 757.72566649512839, 1266.6483462395668, 445.53644881640173, 1071.9875756879514, 699.55062216735973, 1316.5082968743804, 768.50941651964627, 940.93156448186789, 694.00446708144887, 798.92825244666187, 1134.3415274539855, 782.78925929739921, 1304.4793092231612, 1065.547356062453, 730.31883085070388]
mean return 927.069707909
std of return 345.361635099
learning rate: 0.0154303349962
Epoch:  41  avg train loss: 0.159107860197  Reg Loss: 1.55491018272e-06 total time: 1.5734102725982666
avg loss validation: 0.149016364923 failed count: 0
learning rate: 0.0152498570333
Epoch:  42  avg train loss: 0.151506870684  Reg Loss: 1.57066428287e-06 total time: 4.694985628128052
avg loss validation: 0.169202791616 failed count: 1
learning rate: 0.0150755672289
Epoch:  43  avg train loss: 0.159368762918  Reg Loss: 1.58570683543e-06 total time: 6.317338705062866
avg loss validation: 0.14724985211 failed count: 0
learning rate: 0.01490711985
Epoch:  44  avg train loss: 0.146987089595  Reg Loss: 1.60064643986e-06 total time: 9.169071674346924
avg loss validation: 0.154403727193 failed count: 1
learning rate: 0.0147441956155
Epoch:  45  avg train loss: 0.148478046747  Reg Loss: 1.61262289936e-06 total time: 10.79344630241394
avg loss validation: 0.160418368687 failed count: 2
learning rate: 0.0145864991498
Epoch:  46  avg train loss: 0.143505398366  Reg Loss: 1.62536725864e-06 total time: 12.411692142486572
avg loss validation: 0.143050891613 failed count: 0
learning rate: 0.0144337567297
Epoch:  47  avg train loss: 0.142422454672  Reg Loss: 1.6366945326e-06 total time: 15.532780408859253
avg loss validation: 0.14403137519 failed count: 1
learning rate: 0.0142857142857
Epoch:  48  avg train loss: 0.145041831144  Reg Loss: 1.64770712262e-06 total time: 17.154465675354004
avg loss validation: 0.14968973668 failed count: 2
learning rate: 0.0141421356237
Epoch:  49  avg train loss: 0.145174832991  Reg Loss: 1.65874972646e-06 total time: 18.770219326019287
avg loss validation: 0.147453457414 failed count: 3
learning rate: 0.0140028008403
Epoch:  50  avg train loss: 0.134858056248  Reg Loss: 1.67035808024e-06 total time: 20.372965812683105
avg loss validation: 0.144836985002 failed count: 4
iter 0
100/1000
iter 1
100/1000
iter 2
100/1000
200/1000
iter 3
100/1000
iter 4
100/1000
iter 5
100/1000
iter 6
100/1000
iter 7
100/1000
iter 8
100/1000
iter 9
100/1000
iter 10
100/1000
iter 11
100/1000
iter 12
100/1000
200/1000
iter 13
100/1000
iter 14
100/1000
200/1000
iter 15
100/1000
iter 16
100/1000
iter 17
100/1000
200/1000
iter 18
100/1000
iter 19
100/1000
returns [981.9730545809972, 994.52509225975575, 1584.3940940524978, 662.36309304687825, 934.7869238237239, 1045.31879896545, 1169.9146240737887, 1018.588603373796, 1224.4779729115699, 1146.4922802436306, 1097.1803782527227, 815.30508795699961, 1515.9235037481317, 1339.3218826814546, 1570.9620876246345, 878.29830200344179, 1080.9344744561674, 1536.9920786203845, 1355.2701358336403, 1286.8445339742907]
mean return 1161.99335012
std of return 255.684939091
learning rate: 0.0138675049056
Epoch:  51  avg train loss: 0.148428635031  Reg Loss: 1.60959670093e-06 total time: 1.6356568336486816
avg loss validation: 0.134671166073 failed count: 0
learning rate: 0.0137360563949
Epoch:  52  avg train loss: 0.148254197636  Reg Loss: 1.62167486914e-06 total time: 4.569328784942627
avg loss validation: 0.1368195056 failed count: 1
learning rate: 0.0136082763488
Epoch:  53  avg train loss: 0.134170505006  Reg Loss: 1.63164712648e-06 total time: 6.260761260986328
avg loss validation: 0.139378084574 failed count: 2
learning rate: 0.0134839972493
Epoch:  54  avg train loss: 0.14519580087  Reg Loss: 1.64067425198e-06 total time: 7.950341701507568
avg loss validation: 0.133248752818 failed count: 0
learning rate: 0.0133630620956
Epoch:  55  avg train loss: 0.134889995846  Reg Loss: 1.65001107986e-06 total time: 11.125714302062988
avg loss validation: 0.138793823788 failed count: 1
learning rate: 0.0132453235707
Epoch:  56  avg train loss: 0.136446366215  Reg Loss: 1.65815619378e-06 total time: 12.810574531555176
avg loss validation: 0.134861882956 failed count: 2
learning rate: 0.013130643286
Epoch:  57  avg train loss: 0.137757789187  Reg Loss: 1.66674730168e-06 total time: 14.504038333892822
avg loss validation: 0.134679278848 failed count: 3
learning rate: 0.0130188910981
Epoch:  58  avg train loss: 0.135732465713  Reg Loss: 1.6749417062e-06 total time: 16.21341323852539
avg loss validation: 0.15095951327 failed count: 4
learning rate: 0.0129099444874
Epoch:  59  avg train loss: 0.131246393973  Reg Loss: 1.68247552968e-06 total time: 17.906888484954834
avg loss validation: 0.140256409385 failed count: 5
learning rate: 0.0128036879933
Epoch:  60  avg train loss: 0.134118905039  Reg Loss: 1.68966120642e-06 total time: 19.591972827911377
avg loss validation: 0.12861503443 failed count: 0
iter 0
iter 1
100/1000
200/1000
iter 2
100/1000
iter 3
100/1000
200/1000
iter 4
iter 5
100/1000
iter 6
100/1000
iter 7
100/1000
iter 8
100/1000
iter 9
100/1000
iter 10
100/1000
iter 11
100/1000
iter 12
100/1000
iter 13
iter 14
100/1000
200/1000
iter 15
iter 16
iter 17
100/1000
iter 18
100/1000
iter 19
100/1000
200/1000
returns [553.0878349238036, 1815.9129167269573, 744.69142163506319, 1800.5990948791541, 553.35594391844813, 776.43336687971248, 1260.6391093325562, 1306.2993420871435, 1303.2723439329325, 1441.2831459705862, 986.511259237476, 1372.8922304364485, 1452.7958441755761, 302.9802119263843, 2271.8666284136457, 504.92944452279369, 487.08840273663697, 1121.6827390326014, 1117.1010652668324, 1599.7604209749763]
mean return 1138.65913835
std of return 511.328150463
learning rate: 0.0127000127
Epoch:  61  avg train loss: 0.136141348309  Reg Loss: 1.73186863022e-06 total time: 1.8307292461395264
avg loss validation: 0.138242246464 failed count: 0
learning rate: 0.012598815767
Epoch:  62  avg train loss: 0.132956107648  Reg Loss: 1.73974245443e-06 total time: 4.822774171829224
avg loss validation: 0.137569031432 failed count: 0
learning rate: 0.0125
Epoch:  63  avg train loss: 0.133208130305  Reg Loss: 1.74767833896e-06 total time: 7.807417869567871
avg loss validation: 0.128235392429 failed count: 0
learning rate: 0.0124034734589
Epoch:  64  avg train loss: 0.135802051195  Reg Loss: 1.75498413823e-06 total time: 11.0533287525177
avg loss validation: 0.128522110414 failed count: 1
learning rate: 0.0123091490979
Epoch:  65  avg train loss: 0.127327984082  Reg Loss: 1.76257084695e-06 total time: 12.81491756439209
avg loss validation: 0.12771452717 failed count: 0
learning rate: 0.0122169444356
Epoch:  66  avg train loss: 0.131952969103  Reg Loss: 1.76926675176e-06 total time: 16.10393762588501
avg loss validation: 0.131311367413 failed count: 1
learning rate: 0.0121267812518
Epoch:  67  avg train loss: 0.124448838011  Reg Loss: 1.77505527715e-06 total time: 17.860453844070435
avg loss validation: 0.131407839208 failed count: 2
learning rate: 0.0120385853086
Epoch:  68  avg train loss: 0.127951624682  Reg Loss: 1.78111407495e-06 total time: 19.618531227111816
avg loss validation: 0.121645936849 failed count: 0
learning rate: 0.0119522860933
Epoch:  69  avg train loss: 0.126464481531  Reg Loss: 1.78788444564e-06 total time: 22.591121673583984
avg loss validation: 0.120623252571 failed count: 0
learning rate: 0.0118678165819
Epoch:  70  avg train loss: 0.125291427437  Reg Loss: 1.79301579718e-06 total time: 25.878224849700928
avg loss validation: 0.131712009695 failed count: 1
iter 0
iter 1
100/1000
iter 2
100/1000
iter 3
100/1000
iter 4
100/1000
iter 5
100/1000
iter 6
100/1000
200/1000
iter 7
iter 8
100/1000
iter 9
100/1000
iter 10
100/1000
iter 11
100/1000
iter 12
100/1000
200/1000
iter 13
100/1000
iter 14
100/1000
iter 15
iter 16
100/1000
iter 17
100/1000
200/1000
iter 18
iter 19
100/1000
returns [572.70016399079122, 1385.2780229932282, 925.44094854196305, 1528.5755818001594, 844.90004564366268, 1374.2115471272009, 2195.8242258393079, 579.80667045277607, 1453.0283705094578, 1452.3181887831013, 1538.7136591698891, 1507.1279964140654, 1666.1674190703716, 914.16944758040381, 732.679316087713, 537.92241483697762, 1051.2676573065883, 1661.8374112236052, 452.41121034506193, 1448.3816918785194]
mean return 1191.13809948
std of return 463.187041299
learning rate: 0.0117851130198
Epoch:  71  avg train loss: 0.12810009871  Reg Loss: 1.83143721359e-06 total time: 1.8798456192016602
avg loss validation: 0.135277383676 failed count: 0
learning rate: 0.0117041147196
Epoch:  72  avg train loss: 0.131840908464  Reg Loss: 1.83840594023e-06 total time: 4.94909405708313
avg loss validation: 0.134495375506 failed count: 0
learning rate: 0.0116247638744
Epoch:  73  avg train loss: 0.127068295219  Reg Loss: 1.84557215839e-06 total time: 8.031834602355957
avg loss validation: 0.119983137648 failed count: 0
learning rate: 0.0115470053838
Epoch:  74  avg train loss: 0.123926380089  Reg Loss: 1.8511883965e-06 total time: 11.350021362304688
avg loss validation: 0.121709243773 failed count: 1
learning rate: 0.0114707866935
Epoch:  75  avg train loss: 0.124669193798  Reg Loss: 1.85625141882e-06 total time: 13.173840999603271
avg loss validation: 0.126871926684 failed count: 2
learning rate: 0.011396057646
Epoch:  76  avg train loss: 0.120843403562  Reg Loss: 1.8615870385e-06 total time: 15.00123119354248
avg loss validation: 0.123097205059 failed count: 3
learning rate: 0.0113227703414
Epoch:  77  avg train loss: 0.121869287754  Reg Loss: 1.86658503932e-06 total time: 16.832738876342773
avg loss validation: 0.121237862457 failed count: 4
learning rate: 0.0112508790093
Epoch:  78  avg train loss: 0.122540148001  Reg Loss: 1.87186971671e-06 total time: 18.67389440536499
avg loss validation: 0.122048056446 failed count: 5
learning rate: 0.0111803398875
Epoch:  79  avg train loss: 0.122333822465  Reg Loss: 1.87655765504e-06 total time: 20.503534078598022
avg loss validation: 0.136430397166 failed count: 6
iter 0
100/1000
iter 1
100/1000
iter 2
100/1000
iter 3
100/1000
iter 4
100/1000
iter 5
100/1000
iter 6
100/1000
iter 7
iter 8
100/1000
200/1000
iter 9
100/1000
200/1000
iter 10
100/1000
iter 11
100/1000
iter 12
100/1000
iter 13
100/1000
200/1000
iter 14
100/1000
200/1000
iter 15
100/1000
200/1000
iter 16
100/1000
200/1000
300/1000
iter 17
100/1000
200/1000
iter 18
iter 19
100/1000
200/1000
300/1000
returns [953.94386772067799, 825.47836693750992, 907.75096049126716, 1392.047382221175, 1068.1718679775975, 1272.5903232821472, 792.17179074320825, 473.57147219129814, 1689.1060332571369, 1538.409111171904, 1424.0147498756944, 1193.3926578955322, 1226.713061380008, 1894.5630925328785, 1743.442634442554, 1962.3140782161113, 2613.8603943713529, 2154.8112674560907, 447.65104661601356, 2817.1360215772856]
mean return 1419.55700902
std of return 629.723983029
learning rate: 0.0111111111111
Epoch:  80  avg train loss: 0.127673570411  Reg Loss: 1.7714385689e-06 total time: 1.9645991325378418
avg loss validation: 0.119805474325 failed count: 0
learning rate: 0.0110431526075
Epoch:  81  avg train loss: 0.129379555851  Reg Loss: 1.77642686334e-06 total time: 5.11229133605957
avg loss validation: 0.121690516788 failed count: 1
learning rate: 0.010976425999
Epoch:  82  avg train loss: 0.127834810991  Reg Loss: 1.78157017217e-06 total time: 7.0268237590789795
avg loss validation: 0.121492180292 failed count: 2
learning rate: 0.0109108945118
Epoch:  83  avg train loss: 0.126479130012  Reg Loss: 1.78685051539e-06 total time: 8.937922954559326
avg loss validation: 0.123461894476 failed count: 3
learning rate: 0.0108465228909
Epoch:  84  avg train loss: 0.126747350815  Reg Loss: 1.79189208965e-06 total time: 10.834346771240234
avg loss validation: 0.116470190364 failed count: 0
learning rate: 0.0107832773203
Epoch:  85  avg train loss: 0.123439015516  Reg Loss: 1.79704464053e-06 total time: 14.217458724975586
avg loss validation: 0.118475355218 failed count: 1
learning rate: 0.0107211253484
Epoch:  86  avg train loss: 0.125890420451  Reg Loss: 1.80172193399e-06 total time: 16.127206563949585
avg loss validation: 0.127208167013 failed count: 2
learning rate: 0.0106600358178
Epoch:  87  avg train loss: 0.119837409121  Reg Loss: 1.80642455306e-06 total time: 18.0359308719635
avg loss validation: 0.12076941481 failed count: 3
learning rate: 0.0105999788001
Epoch:  88  avg train loss: 0.124953046567  Reg Loss: 1.81095336759e-06 total time: 19.945135593414307
avg loss validation: 0.113903010774 failed count: 0
learning rate: 0.0105409255339
Epoch:  89  avg train loss: 0.122804687182  Reg Loss: 1.81531427087e-06 total time: 23.361449480056763
avg loss validation: 0.117776932194 failed count: 1
iter 0
100/1000
iter 1
100/1000
iter 2
100/1000
iter 3
100/1000
iter 4
100/1000
200/1000
300/1000
iter 5
100/1000
200/1000
iter 6
100/1000
200/1000
iter 7
100/1000
iter 8
100/1000
iter 9
100/1000
200/1000
iter 10
iter 11
100/1000
200/1000
iter 12
100/1000
200/1000
iter 13
iter 14
100/1000
iter 15
100/1000
200/1000
iter 16
100/1000
200/1000
iter 17
100/1000
iter 18
100/1000
iter 19
100/1000
returns [1401.6648516602268, 1323.4538972934072, 797.69890895577521, 1139.2735034654174, 2634.619278808063, 2091.1384726743636, 1993.0422636466581, 775.99571825429507, 860.39259225472392, 1663.8105089552776, 494.26622580848903, 2136.0289363850229, 1901.7657950491914, 466.30086768429231, 1475.9992019068004, 2491.7336856067068, 1884.2570753766011, 874.65233214900354, 732.36870851674666, 1371.49555486399]
mean return 1425.49791897
std of return 639.052680545
learning rate: 0.0104828483672
Epoch:  90  avg train loss: 0.122945703286  Reg Loss: 1.84168274544e-06 total time: 2.056284189224243
avg loss validation: 0.121035559834 failed count: 0
learning rate: 0.0104257207029
Epoch:  91  avg train loss: 0.123146863434  Reg Loss: 1.84674792013e-06 total time: 5.271839380264282
avg loss validation: 0.119166411766 failed count: 0
learning rate: 0.0103695169473
Epoch:  92  avg train loss: 0.121286996558  Reg Loss: 1.8515236681e-06 total time: 8.47164011001587
avg loss validation: 0.125352230208 failed count: 1
learning rate: 0.0103142124626
Epoch:  93  avg train loss: 0.119407092797  Reg Loss: 1.85553639454e-06 total time: 10.46134066581726
avg loss validation: 0.120430430626 failed count: 2
learning rate: 0.0102597835209
Epoch:  94  avg train loss: 0.120516796168  Reg Loss: 1.85966870483e-06 total time: 12.459078073501587
avg loss validation: 0.121521839787 failed count: 3
learning rate: 0.0102062072616
Epoch:  95  avg train loss: 0.117585121896  Reg Loss: 1.86375342551e-06 total time: 14.461441040039062
avg loss validation: 0.129362163008 failed count: 4
learning rate: 0.0101534616513
Epoch:  96  avg train loss: 0.118759075325  Reg Loss: 1.86789349097e-06 total time: 16.46176266670227
avg loss validation: 0.115609410597 failed count: 0
learning rate: 0.0101015254455
Epoch:  97  avg train loss: 0.118162659624  Reg Loss: 1.87199524081e-06 total time: 19.938791275024414
avg loss validation: 0.118210505048 failed count: 1
learning rate: 0.0100503781526
Epoch:  98  avg train loss: 0.114179601318  Reg Loss: 1.87530567541e-06 total time: 21.937363147735596
avg loss validation: 0.120930724142 failed count: 2
learning rate: 0.01
Epoch:  99  avg train loss: 0.117074378081  Reg Loss: 1.87842380704e-06 total time: 23.92878770828247
avg loss validation: 0.11693829833 failed count: 3
iter 0
100/1000
200/1000
iter 1
100/1000
200/1000
iter 2
100/1000
200/1000
iter 3
100/1000
200/1000
iter 4
100/1000
200/1000
iter 5
100/1000
200/1000
iter 6
100/1000
200/1000
300/1000
iter 7
iter 8
100/1000
iter 9
100/1000
200/1000
iter 10
100/1000
200/1000
iter 11
100/1000
iter 12
100/1000
iter 13
100/1000
iter 14
100/1000
iter 15
100/1000
200/1000
iter 16
100/1000
iter 17
100/1000
iter 18
iter 19
100/1000
returns [1694.0419352683764, 1916.0670367964976, 2126.585658275495, 1721.3744926366355, 1818.7333642896933, 1609.8941944171606, 2615.0209068846684, 599.89802946442455, 910.30425994162101, 1990.5929349089199, 1834.8989527080184, 1118.0095165157131, 1500.9945103158464, 1429.23903244645, 1518.3437748799104, 1929.5462806513217, 1347.1298097104793, 867.79946621455565, 587.43774347175486, 1541.0677367467747]
mean return 1533.84898183
std of return 504.501857413
learning rate: 0.0099503719021
Epoch:  100  avg train loss: 0.118539658714  Reg Loss: 1.89922898628e-06 total time: 2.915738582611084
avg loss validation: 0.119260262348 failed count: 0
learning rate: 0.00990147542977
Epoch:  101  avg train loss: 0.117722643904  Reg Loss: 1.90379822806e-06 total time: 6.610307455062866
avg loss validation: 0.116435967642 failed count: 0
learning rate: 0.00985329278164
Epoch:  102  avg train loss: 0.117276293667  Reg Loss: 1.9081973145e-06 total time: 10.019922494888306
avg loss validation: 0.116088667549 failed count: 0
learning rate: 0.00980580675691
Epoch:  103  avg train loss: 0.11562897571  Reg Loss: 1.91224484362e-06 total time: 13.778046369552612
avg loss validation: 0.118714662712 failed count: 1
learning rate: 0.00975900072949
Epoch:  104  avg train loss: 0.119908506341  Reg Loss: 1.91600306899e-06 total time: 15.908572912216187
avg loss validation: 0.125775112242 failed count: 2
learning rate: 0.00971285862357
Epoch:  105  avg train loss: 0.112866746046  Reg Loss: 1.92017651658e-06 total time: 17.983590364456177
avg loss validation: 0.116125855922 failed count: 3
learning rate: 0.00966736489046
Epoch:  106  avg train loss: 0.114274457422  Reg Loss: 1.92366095197e-06 total time: 20.063793182373047
avg loss validation: 0.114169177994 failed count: 0
learning rate: 0.00962250448649
Epoch:  107  avg train loss: 0.11155863247  Reg Loss: 1.92701318398e-06 total time: 23.42767357826233
avg loss validation: 0.121247026347 failed count: 1
learning rate: 0.00957826285221
Epoch:  108  avg train loss: 0.112717284916  Reg Loss: 1.92989399355e-06 total time: 25.508568048477173
avg loss validation: 0.11132336918 failed count: 0
learning rate: 0.00953462589246
Epoch:  109  avg train loss: 0.115421555333  Reg Loss: 1.93281961334e-06 total time: 29.075164556503296
avg loss validation: 0.124662413825 failed count: 1
iter 0
100/1000
iter 1
100/1000
iter 2
100/1000
iter 3
100/1000
iter 4
100/1000
iter 5
100/1000
iter 6
100/1000
200/1000
iter 7
100/1000
iter 8
100/1000
iter 9
100/1000
iter 10
100/1000
iter 11
100/1000
iter 12
100/1000
iter 13
100/1000
200/1000
iter 14
iter 15
100/1000
iter 16
100/1000
iter 17
100/1000
iter 18
100/1000
iter 19
100/1000
returns [1350.0606119646918, 1097.0330400525384, 1498.1652628592276, 780.75272492386841, 744.84072319339805, 1332.9300097807529, 1751.9308139974833, 1337.9932118654231, 650.63256711699307, 1407.2734010065333, 838.43051296502119, 812.54194638462536, 1096.718103044979, 2131.8592778007719, 348.74350950786453, 1331.5331493834317, 668.97899525479613, 864.24395904418998, 1209.0834465568671, 748.75887671059502]
mean return 1100.12520717
std of return 417.840209451
learning rate: 0.00949157995752
Epoch:  110  avg train loss: 0.110633042674  Reg Loss: 1.97153329655e-06 total time: 2.172208070755005
avg loss validation: 0.118502662544 failed count: 0
learning rate: 0.00944911182523
Epoch:  111  avg train loss: 0.114015354517  Reg Loss: 1.97459334422e-06 total time: 5.5863356590271
avg loss validation: 0.116309014552 failed count: 0
learning rate: 0.00940720868384
Epoch:  112  avg train loss: 0.111079310796  Reg Loss: 1.97785619582e-06 total time: 9.030340671539307
avg loss validation: 0.109895037803 failed count: 0
learning rate: 0.00936585811582
Epoch:  113  avg train loss: 0.11024504479  Reg Loss: 1.98105149599e-06 total time: 12.717974662780762
avg loss validation: 0.106278054973 failed count: 0
learning rate: 0.0093250480824
Epoch:  114  avg train loss: 0.110808671458  Reg Loss: 1.98361441003e-06 total time: 16.34501314163208
avg loss validation: 0.108745690488 failed count: 1
learning rate: 0.00928476690885
Epoch:  115  avg train loss: 0.108819335633  Reg Loss: 1.98664797156e-06 total time: 18.47843337059021
avg loss validation: 0.114179414814 failed count: 2
learning rate: 0.00924500327042
Epoch:  116  avg train loss: 0.109512043448  Reg Loss: 1.98960935353e-06 total time: 20.70586633682251
avg loss validation: 0.109663556083 failed count: 3
learning rate: 0.00920574617898
Epoch:  117  avg train loss: 0.104917032657  Reg Loss: 1.99203018512e-06 total time: 22.863253593444824
avg loss validation: 0.112047280714 failed count: 4
learning rate: 0.00916698497028
Epoch:  118  avg train loss: 0.110095366388  Reg Loss: 1.99496492061e-06 total time: 25.016335487365723
avg loss validation: 0.106833642675 failed count: 5
learning rate: 0.00912870929175
Epoch:  119  avg train loss: 0.107499277664  Reg Loss: 1.99725960632e-06 total time: 27.237523317337036
avg loss validation: 0.111693102452 failed count: 6
iter 0
100/1000
200/1000
iter 1
100/1000
iter 2
iter 3
100/1000
200/1000
iter 4
100/1000
iter 5
100/1000
200/1000
iter 6
100/1000
200/1000
iter 7
100/1000
200/1000
300/1000
iter 8
100/1000
200/1000
iter 9
100/1000
200/1000
300/1000
iter 10
100/1000
200/1000
iter 11
100/1000
200/1000
iter 12
100/1000
iter 13
100/1000
200/1000
iter 14
100/1000
200/1000
iter 15
100/1000
iter 16
100/1000
iter 17
iter 18
100/1000
200/1000
iter 19
100/1000
200/1000
returns [2391.9925195012211, 1460.2669058691615, 605.49543847505731, 1619.6303166199202, 1286.3393876066441, 2078.2315317974799, 2228.169826519937, 3489.3887871835309, 1742.0521134371668, 2572.7206412816072, 1927.0415979285385, 1720.6187755023147, 860.29706996546781, 1626.6408543743064, 1770.1398172726899, 762.40799220958752, 958.68544601493568, 580.01783300824764, 2128.1177367191071, 1697.48127325466]
mean return 1675.28679323
std of return 704.294760309
learning rate: 0.00909090909091
Epoch:  120  avg train loss: 0.10916120496  Reg Loss: 2.00846345324e-06 total time: 2.281994342803955
avg loss validation: 0.107547366219 failed count: 0
learning rate: 0.00905357460425
Epoch:  121  avg train loss: 0.110424240944  Reg Loss: 2.01134701692e-06 total time: 5.822306156158447
avg loss validation: 0.106770569999 failed count: 0
learning rate: 0.00901669634667
Epoch:  122  avg train loss: 0.10596323878  Reg Loss: 2.01427655666e-06 total time: 9.30237889289856
avg loss validation: 0.10756948167 failed count: 1
learning rate: 0.00898026510134
Epoch:  123  avg train loss: 0.108337255367  Reg Loss: 2.01647657472e-06 total time: 11.536970853805542
avg loss validation: 0.124997820184 failed count: 2
learning rate: 0.00894427191
Epoch:  124  avg train loss: 0.106723403129  Reg Loss: 2.01916655336e-06 total time: 13.782788276672363
avg loss validation: 0.106815650166 failed count: 3
learning rate: 0.00890870806375
Epoch:  125  avg train loss: 0.107680944231  Reg Loss: 2.02123570151e-06 total time: 16.13498854637146
avg loss validation: 0.108686759664 failed count: 4
learning rate: 0.00887356509416
Epoch:  126  avg train loss: 0.103419384738  Reg Loss: 2.02400643534e-06 total time: 18.469103574752808
avg loss validation: 0.10904514452 failed count: 5
learning rate: 0.00883883476483
Epoch:  127  avg train loss: 0.107547194783  Reg Loss: 2.02579808804e-06 total time: 20.69867205619812
avg loss validation: 0.102241382246 failed count: 0
learning rate: 0.00880450906326
Epoch:  128  avg train loss: 0.104338010357  Reg Loss: 2.02787895557e-06 total time: 24.48863649368286
avg loss validation: 0.103419555544 failed count: 1
learning rate: 0.00877058019307
Epoch:  129  avg train loss: 0.103279822338  Reg Loss: 2.03020361507e-06 total time: 26.720218658447266
avg loss validation: 0.106767886587 failed count: 2
iter 0
100/1000
200/1000
iter 1
100/1000
iter 2
iter 3
100/1000
200/1000
iter 4
100/1000
200/1000
iter 5
100/1000
200/1000
300/1000
iter 6
100/1000
200/1000
iter 7
100/1000
200/1000
iter 8
100/1000
iter 9
100/1000
200/1000
iter 10
iter 11
100/1000
200/1000
iter 12
100/1000
iter 13
100/1000
200/1000
300/1000
400/1000
iter 14
100/1000
200/1000
iter 15
100/1000
200/1000
iter 16
100/1000
iter 17
iter 18
100/1000
200/1000
iter 19
100/1000
200/1000
returns [1799.9346047811055, 1408.1297670963097, 582.07120542017844, 2174.3292932623476, 2444.8955814222595, 3127.6510720250108, 2306.8985272379236, 2236.8299365011662, 892.71635916935384, 1812.4501892934688, 398.35608109832674, 1718.1727472012637, 1225.0470017647581, 4151.0889565889429, 1881.9816224627318, 2371.1927556530391, 1026.6528564883365, 338.82077030550835, 2247.4344588085978, 1793.2148317967044]
mean return 1796.89343092
std of return 903.390916921
learning rate: 0.00873704056661
Epoch:  130  avg train loss: 0.107000602381  Reg Loss: 2.03565763313e-06 total time: 2.4074459075927734
avg loss validation: 0.108168049419 failed count: 0
learning rate: 0.00870388279778
Epoch:  131  avg train loss: 0.105079875957  Reg Loss: 2.03841184587e-06 total time: 6.3330700397491455
avg loss validation: 0.106520379123 failed count: 0
learning rate: 0.00867109969524
Epoch:  132  avg train loss: 0.102127483388  Reg Loss: 2.04019085933e-06 total time: 9.876330614089966
avg loss validation: 0.10721254688 failed count: 1
learning rate: 0.00863868425581
Epoch:  133  avg train loss: 0.1071652893  Reg Loss: 2.04297462088e-06 total time: 12.21005892753601
avg loss validation: 0.101121424299 failed count: 0
learning rate: 0.00860662965824
Epoch:  134  avg train loss: 0.104154335684  Reg Loss: 2.04516383394e-06 total time: 16.098769664764404
avg loss validation: 0.103181651182 failed count: 1
learning rate: 0.00857492925713
Epoch:  135  avg train loss: 0.103642723758  Reg Loss: 2.04697495758e-06 total time: 18.5381977558136
avg loss validation: 0.104677993294 failed count: 2
learning rate: 0.00854357657717
Epoch:  136  avg train loss: 0.0995372773402  Reg Loss: 2.0488169843e-06 total time: 20.96116828918457
avg loss validation: 0.101186226012 failed count: 3
learning rate: 0.00851256530759
Epoch:  137  avg train loss: 0.103417241424  Reg Loss: 2.05057983473e-06 total time: 23.303661823272705
avg loss validation: 0.103573378274 failed count: 4
learning rate: 0.0084818892968
Epoch:  138  avg train loss: 0.10298718763  Reg Loss: 2.05263841866e-06 total time: 25.742186546325684
avg loss validation: 0.101364538548 failed count: 5
learning rate: 0.00845154254729
Epoch:  139  avg train loss: 0.0996829370175  Reg Loss: 2.0546246762e-06 total time: 28.17695641517639
avg loss validation: 0.101412090129 failed count: 6
iter 0
100/1000
200/1000
iter 1
100/1000
200/1000
iter 2
100/1000
200/1000
300/1000
iter 3
100/1000
200/1000
iter 4
100/1000
200/1000
300/1000
iter 5
100/1000
200/1000
300/1000
iter 6
100/1000
iter 7
100/1000
200/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
iter 9
100/1000
iter 10
100/1000
200/1000
iter 11
100/1000
iter 12
100/1000
200/1000
300/1000
400/1000
iter 13
100/1000
iter 14
100/1000
iter 15
100/1000
200/1000
iter 16
100/1000
200/1000
300/1000
iter 17
100/1000
iter 18
100/1000
iter 19
100/1000
200/1000
returns [2031.9040672042374, 2148.8314352794268, 3037.9558498586857, 2115.0478272366954, 3104.9182300009252, 2714.5904746732012, 899.73833057212789, 2138.3603860344724, 4506.3162250056557, 818.67340282569592, 2132.0025928053856, 864.99053727368664, 4054.3054559037928, 1369.5651195780445, 767.17024971620333, 2181.5376370218833, 3170.7042242284656, 1603.5832952258843, 1108.4638223369323, 2000.4693786215425]
mean return 2138.45642707
std of return 1028.77006605
learning rate: 0.00842151921067
Epoch:  140  avg train loss: 0.104592555538  Reg Loss: 2.04411134434e-06 total time: 2.4907734394073486
avg loss validation: 0.105022868285 failed count: 0
learning rate: 0.00839181358297
Epoch:  141  avg train loss: 0.104035104494  Reg Loss: 2.04676281048e-06 total time: 6.236914157867432
avg loss validation: 0.106657150725 failed count: 1
learning rate: 0.00836242010007
Epoch:  142  avg train loss: 0.105088259574  Reg Loss: 2.04840126548e-06 total time: 8.764754056930542
avg loss validation: 0.102380338962 failed count: 0
learning rate: 0.00833333333333
Epoch:  143  avg train loss: 0.100487066064  Reg Loss: 2.05053972406e-06 total time: 12.919374227523804
avg loss validation: 0.110613142532 failed count: 1
learning rate: 0.00830454798537
Epoch:  144  avg train loss: 0.102759310301  Reg Loss: 2.05248254329e-06 total time: 15.479472160339355
avg loss validation: 0.101060231314 failed count: 0
learning rate: 0.00827605888602
Epoch:  145  avg train loss: 0.10125461278  Reg Loss: 2.05482500827e-06 total time: 19.228458404541016
avg loss validation: 0.101111295016 failed count: 1
learning rate: 0.00824786098842
Epoch:  146  avg train loss: 0.0989873482335  Reg Loss: 2.05603835179e-06 total time: 21.934640407562256
avg loss validation: 0.109387653947 failed count: 2
learning rate: 0.00821994936527
