3.6.0 |Anaconda custom (64-bit)| (default, Dec 23 2016, 12:22:00) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]
loading and building expert policy
obs (1, 376) (1, 376)
loaded and built
iter 0
iter 1
iter 2
iter 3
iter 4
iter 5
iter 6
iter 7
iter 8
iter 9
iter 10
iter 11
iter 12
iter 13
iter 14
iter 15
iter 16
iter 17
iter 18
iter 19
returns [81.224484459695049, 81.14863958036706, 81.522740171157423, 76.360535824632336, 86.257860380305303, 81.320618557053393, 81.168477116761309, 81.453003038144914, 86.18977872072, 81.297169367304306, 86.294504370649406, 81.143592397018224, 81.118163162447843, 76.613072536071869, 81.109337170769891, 81.537170673692131, 81.226523173908035, 81.153422532867467, 80.121193172756477, 81.247623596744532]
mean return 81.4753955002
std of return 2.45839808707
learning rate: 0.0707106781187
Epoch:  1  avg train loss: 2.52812172067  Reg Loss: 9.67249411462e-07 total time: 11.359203815460205
avg loss validation: 0.640842027809 failed count: 0
learning rate: 0.057735026919
Epoch:  2  avg train loss: 0.552224632217  Reg Loss: 1.21627217425e-06 total time: 25.017876863479614
avg loss validation: 0.466531093845 failed count: 0
learning rate: 0.05
Epoch:  3  avg train loss: 0.448186201622  Reg Loss: 1.49561922477e-06 total time: 38.276036500930786
avg loss validation: 0.417180467177 failed count: 0
learning rate: 0.04472135955
Epoch:  4  avg train loss: 0.392506021238  Reg Loss: 1.75565000874e-06 total time: 51.51406216621399
avg loss validation: 0.373125997152 failed count: 0
learning rate: 0.0408248290464
Epoch:  5  avg train loss: 0.362700666699  Reg Loss: 1.97781380845e-06 total time: 65.15917301177979
avg loss validation: 0.460448035997 failed count: 1
iter 0
iter 1
iter 2
iter 3
iter 4
iter 5
iter 6
iter 7
iter 8
iter 9
iter 10
iter 11
iter 12
iter 13
iter 14
iter 15
iter 16
iter 17
iter 18
iter 19
returns [233.30394084428545, 231.50426242129464, 212.90424555007405, 224.14595277067997, 259.06233902047296, 220.64631866832852, 234.59130097232207, 237.61643961134405, 215.820950383764, 244.03676551089899, 243.52999232008824, 242.00457906457797, 259.09885933129419, 236.00242629787317, 234.61842779963024, 229.03181693846449, 202.63400580892196, 227.92312954404665, 233.70063041805767, 209.03612806243507]
mean return 231.560625567
std of return 14.3855483606
learning rate: 0.0377964473009
Epoch:  6  avg train loss: 0.342662833166  Reg Loss: 2.15721333138e-06 total time: 11.185813426971436
avg loss validation: 0.299681925114 failed count: 0
learning rate: 0.0353553390593
Epoch:  7  avg train loss: 0.299997791422  Reg Loss: 2.32224615085e-06 total time: 24.97679829597473
avg loss validation: 0.420643710301 failed count: 1
learning rate: 0.0333333333333
Epoch:  8  avg train loss: 0.298964756247  Reg Loss: 2.46718384249e-06 total time: 36.52137851715088
avg loss validation: 0.325456295115 failed count: 2
learning rate: 0.0316227766017
Epoch:  9  avg train loss: 0.279635912144  Reg Loss: 2.59221919798e-06 total time: 48.27566599845886
avg loss validation: 0.265963383355 failed count: 0
learning rate: 0.0301511344578
Epoch:  10  avg train loss: 0.259296071297  Reg Loss: 2.70636204096e-06 total time: 61.572190046310425
avg loss validation: 0.252251612487 failed count: 0
iter 0
iter 1
100/1000
iter 2
100/1000
iter 3
iter 4
100/1000
200/1000
iter 5
100/1000
iter 6
100/1000
iter 7
100/1000
iter 8
100/1000
iter 9
100/1000
iter 10
100/1000
iter 11
100/1000
iter 12
100/1000
iter 13
100/1000
iter 14
100/1000
iter 15
iter 16
100/1000
iter 17
iter 18
100/1000
iter 19
100/1000
returns [530.5345744715828, 903.86179513943728, 867.1798873909446, 578.03799954663407, 1267.3936079901325, 695.69592033350023, 802.39310867697839, 961.88518429530814, 618.25960230480882, 765.52882841811345, 649.6696010270349, 617.69074774316346, 946.57301205424733, 1069.1766915956848, 802.46423209847376, 452.57290915251491, 1041.802233655912, 529.77696549212624, 646.78077190484532, 767.60031085466915]
mean return 775.743899207
std of return 205.143907249
learning rate: 0.0288675134595
Epoch:  11  avg train loss: 0.278890509989  Reg Loss: 2.86597897869e-06 total time: 11.453579902648926
avg loss validation: 0.263339402195 failed count: 0
learning rate: 0.0277350098113
Epoch:  12  avg train loss: 0.247721349167  Reg Loss: 2.97932427763e-06 total time: 25.456716299057007
avg loss validation: 0.243701511467 failed count: 0
learning rate: 0.0267261241912
Epoch:  13  avg train loss: 0.244423973237  Reg Loss: 3.07141284999e-06 total time: 39.03401780128479
avg loss validation: 0.275414149875 failed count: 1
learning rate: 0.0258198889747
Epoch:  14  avg train loss: 0.236306612969  Reg Loss: 3.15745347626e-06 total time: 50.87952518463135
avg loss validation: 0.23557643391 failed count: 0
learning rate: 0.025
Epoch:  15  avg train loss: 0.23286267299  Reg Loss: 3.23683329374e-06 total time: 64.94643259048462
avg loss validation: 0.213435619557 failed count: 0
iter 0
100/1000
iter 1
100/1000
iter 2
100/1000
iter 3
100/1000
200/1000
iter 4
100/1000
200/1000
iter 5
100/1000
iter 6
100/1000
200/1000
iter 7
iter 8
100/1000
iter 9
100/1000
iter 10
100/1000
200/1000
iter 11
100/1000
iter 12
100/1000
iter 13
100/1000
200/1000
iter 14
100/1000
200/1000
300/1000
iter 15
100/1000
iter 16
100/1000
iter 17
100/1000
iter 18
100/1000
iter 19
100/1000
returns [1141.957495049355, 746.94724032488216, 1216.6706033247765, 1690.8627532569853, 1385.3360873314441, 1081.6388488379753, 1964.922783953529, 580.86157671732769, 1248.91935836827, 966.80019577477026, 1537.3059498845571, 1196.1930318897655, 881.1055177579658, 1485.2349291343962, 2265.5479379511762, 978.63597830806316, 1206.0347639671913, 800.30212427367087, 1323.771348202368, 1334.6429594399779]
mean return 1251.68457419
std of return 396.514633342
learning rate: 0.0242535625036
Epoch:  16  avg train loss: 0.228568067136  Reg Loss: 3.20866831968e-06 total time: 11.820615768432617
avg loss validation: 0.21847011292 failed count: 0
learning rate: 0.0235702260396
Epoch:  17  avg train loss: 0.220928331321  Reg Loss: 3.27677941842e-06 total time: 26.276345252990723
avg loss validation: 0.210152822812 failed count: 0
learning rate: 0.0229415733871
Epoch:  18  avg train loss: 0.215199501179  Reg Loss: 3.33761318432e-06 total time: 40.69077157974243
avg loss validation: 0.216828881997 failed count: 1
learning rate: 0.022360679775
Epoch:  19  avg train loss: 0.21216917543  Reg Loss: 3.39579402517e-06 total time: 52.92118954658508
avg loss validation: 0.197262273943 failed count: 0
learning rate: 0.0218217890236
Epoch:  20  avg train loss: 0.202102038031  Reg Loss: 3.44866353028e-06 total time: 67.20165467262268
avg loss validation: 0.217005700699 failed count: 1
iter 0
100/1000
iter 1
100/1000
iter 2
100/1000
200/1000
iter 3
100/1000
iter 4
100/1000
iter 5
100/1000
200/1000
iter 6
100/1000
iter 7
100/1000
200/1000
iter 8
100/1000
iter 9
100/1000
iter 10
100/1000
200/1000
300/1000
iter 11
100/1000
iter 12
100/1000
iter 13
100/1000
iter 14
100/1000
iter 15
100/1000
iter 16
100/1000
iter 17
100/1000
iter 18
100/1000
iter 19
100/1000
returns [1260.160916135746, 863.13070987006449, 1680.8543529175022, 879.47751930991024, 883.7051012276454, 1439.4907579194457, 1048.9333297998437, 1784.0064494344522, 761.06000274992891, 1042.6356758033598, 2515.6204644937247, 1047.086617503928, 606.93739136758791, 881.2620245438776, 669.09497176282468, 958.33512180188416, 1081.999825520988, 1203.6867342841499, 1130.547779187498, 1165.483272463327]
mean return 1145.1754509
std of return 429.966718753
learning rate: 0.0213200716356
Epoch:  21  avg train loss: 0.212242859031  Reg Loss: 3.53709925927e-06 total time: 12.51911973953247
avg loss validation: 0.203545736797 failed count: 0
learning rate: 0.0208514414057
Epoch:  22  avg train loss: 0.196957164492  Reg Loss: 3.59306031169e-06 total time: 26.816561460494995
avg loss validation: 0.247323076159 failed count: 1
learning rate: 0.0204124145232
Epoch:  23  avg train loss: 0.199882054306  Reg Loss: 3.64183645061e-06 total time: 39.369361877441406
avg loss validation: 0.186126879113 failed count: 0
learning rate: 0.02
Epoch:  24  avg train loss: 0.192947469973  Reg Loss: 3.68230697745e-06 total time: 54.12714743614197
avg loss validation: 0.201798314286 failed count: 1
learning rate: 0.0196116135138
Epoch:  25  avg train loss: 0.18955433941  Reg Loss: 3.7236692701e-06 total time: 66.75538158416748
avg loss validation: 0.231667653264 failed count: 2
iter 0
100/1000
200/1000
iter 1
100/1000
iter 2
100/1000
iter 3
100/1000
iter 4
100/1000
iter 5
100/1000
200/1000
300/1000
iter 6
100/1000
iter 7
100/1000
iter 8
iter 9
100/1000
iter 10
100/1000
iter 11
100/1000
200/1000
iter 12
100/1000
iter 13
iter 14
iter 15
100/1000
iter 16
100/1000
iter 17
100/1000
iter 18
100/1000
200/1000
iter 19
returns [1748.1172530799142, 1251.284491129702, 640.72042624563767, 1058.8519365237862, 1218.3059877035951, 2419.9862576895225, 809.33364753827777, 925.73987569651263, 447.80765235950781, 726.82721224396494, 790.82821439466068, 1874.0127123107718, 796.68611539728738, 443.82929461751399, 536.4425885185932, 846.33475736457535, 1127.3987640873972, 1269.3004293291697, 2197.7434307405906, 401.42799146159865]
mean return 1076.54895192
std of return 565.775714006
learning rate: 0.019245008973
Epoch:  26  avg train loss: 0.190521398539  Reg Loss: 3.80891789828e-06 total time: 12.891714096069336
avg loss validation: 0.175354081701 failed count: 0
learning rate: 0.0188982236505
Epoch:  27  avg train loss: 0.186149991875  Reg Loss: 3.84775548815e-06 total time: 28.01975655555725
avg loss validation: 0.197999629152 failed count: 1
learning rate: 0.0185695338177
Epoch:  28  avg train loss: 0.179379705467  Reg Loss: 3.88359504997e-06 total time: 40.8999285697937
avg loss validation: 0.171898862834 failed count: 0
learning rate: 0.0182574185835
Epoch:  29  avg train loss: 0.180139463375  Reg Loss: 3.91421437606e-06 total time: 55.533940076828
avg loss validation: 0.18235453341 failed count: 1
learning rate: 0.0179605302027
Epoch:  30  avg train loss: 0.171582153944  Reg Loss: 3.94457954237e-06 total time: 68.43747186660767
avg loss validation: 0.156300897682 failed count: 0
iter 0
100/1000
200/1000
iter 1
100/1000
iter 2
100/1000
200/1000
300/1000
400/1000
iter 3
100/1000
iter 4
100/1000
200/1000
300/1000
400/1000
500/1000
iter 5
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 6
100/1000
200/1000
300/1000
iter 7
100/1000
iter 8
100/1000
200/1000
iter 9
100/1000
200/1000
iter 10
100/1000
200/1000
iter 11
100/1000
200/1000
300/1000
iter 12
100/1000
200/1000
300/1000
iter 13
100/1000
200/1000
iter 14
100/1000
iter 15
100/1000
iter 16
100/1000
iter 17
100/1000
iter 18
100/1000
200/1000
iter 19
100/1000
returns [1904.265416948849, 968.8300420598066, 3199.2770159131378, 1440.658916788999, 4072.8825725178731, 5963.9996373091335, 3021.8209960099348, 1054.1252798693235, 1568.4818961414383, 2154.7379167036806, 2154.5151135548899, 2207.535749212946, 2460.958811814337, 1828.7328882360532, 959.09871488209797, 704.74835734475232, 1200.613500924308, 711.60602247108693, 1786.179195207761, 1231.737975248948]
mean return 2029.74030096
std of return 1244.38410986
learning rate: 0.0176776695297
Epoch:  31  avg train loss: 0.185733863608  Reg Loss: 3.94180232438e-06 total time: 13.003581285476685
avg loss validation: 0.167251649452 failed count: 0
learning rate: 0.0174077655956
Epoch:  32  avg train loss: 0.167984204213  Reg Loss: 3.97360980366e-06 total time: 28.64993119239807
avg loss validation: 0.175806737165 failed count: 1
learning rate: 0.0171498585143
Epoch:  33  avg train loss: 0.167786263689  Reg Loss: 3.99445593306e-06 total time: 42.100648164749146
avg loss validation: 0.153351069629 failed count: 0
learning rate: 0.0169030850946
Epoch:  34  avg train loss: 0.166579542395  Reg Loss: 4.01376847114e-06 total time: 57.33456611633301
avg loss validation: 0.178507917698 failed count: 1
learning rate: 0.0166666666667
Epoch:  35  avg train loss: 0.165769378957  Reg Loss: 4.03426029589e-06 total time: 70.77266597747803
avg loss validation: 0.151632638979 failed count: 0
iter 0
100/1000
iter 1
100/1000
iter 2
100/1000
200/1000
300/1000
iter 3
100/1000
200/1000
300/1000
400/1000
iter 4
100/1000
200/1000
300/1000
iter 5
100/1000
200/1000
300/1000
400/1000
iter 6
100/1000
iter 7
100/1000
200/1000
300/1000
400/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
iter 9
100/1000
iter 10
100/1000
iter 11
100/1000
iter 12
100/1000
iter 13
100/1000
200/1000
iter 14
100/1000
200/1000
iter 15
100/1000
iter 16
100/1000
iter 17
100/1000
200/1000
300/1000
iter 18
iter 19
100/1000
returns [979.95371344467958, 936.26786085911783, 2480.6114609756187, 3191.4723756231697, 2988.8817232400897, 3393.0488690869311, 993.55383019442797, 3158.5610752058183, 4451.3257917078281, 721.43785290824815, 830.37899338964996, 1301.9545584421219, 1035.0073783133932, 1551.9330271941983, 1479.1288098261789, 1313.5059940042656, 825.59441971344711, 2495.8219125911437, 532.26584175806568, 1131.6469789117325]
mean return 1789.61762337
std of return 1098.13417361
learning rate: 0.0164398987305
Epoch:  36  avg train loss: 0.162474335593  Reg Loss: 4.04553227918e-06 total time: 13.572719097137451
avg loss validation: 0.166583085204 failed count: 0
learning rate: 0.0162221421131
Epoch:  37  avg train loss: 0.161119991713  Reg Loss: 4.06330101522e-06 total time: 29.975618600845337
avg loss validation: 0.158718028068 failed count: 0
learning rate: 0.0160128153805
Epoch:  38  avg train loss: 0.160515717042  Reg Loss: 4.08090700861e-06 total time: 46.4853618144989
avg loss validation: 0.143920038429 failed count: 0
learning rate: 0.0158113883008
Epoch:  39  avg train loss: 0.156278566807  Reg Loss: 4.09860080783e-06 total time: 62.17877221107483
avg loss validation: 0.154394479045 failed count: 1
learning rate: 0.0156173761889
Epoch:  40  avg train loss: 0.152294728024  Reg Loss: 4.11126453283e-06 total time: 76.11611914634705
avg loss validation: 0.141728423673 failed count: 0
iter 0
100/1000
200/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 2
100/1000
200/1000
iter 3
100/1000
200/1000
300/1000
iter 4
100/1000
200/1000
300/1000
iter 5
100/1000
200/1000
300/1000
400/1000
iter 6
100/1000
200/1000
iter 7
100/1000
200/1000
iter 8
100/1000
200/1000
300/1000
400/1000
iter 9
100/1000
200/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 11
100/1000
200/1000
300/1000
iter 12
100/1000
200/1000
300/1000
400/1000
500/1000
iter 13
100/1000
200/1000
iter 14
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 15
100/1000
200/1000
300/1000
400/1000
iter 16
100/1000
iter 17
100/1000
200/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 19
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
returns [1463.5637276541609, 7076.2694109831828, 2016.3095930318516, 2917.5937185265998, 2451.2757922492542, 3601.7840923450167, 1932.7820514734619, 1784.6074618190792, 3364.9015429345168, 1967.6787065839742, 5436.2393736370104, 3025.2751886258584, 4359.0933823298774, 1837.2287577867628, 6632.0166569378234, 3796.8713977434259, 1043.9792841307283, 2153.5405844280544, 5669.5016540285887, 5934.2588913976087]
mean return 3423.23856343
std of return 1790.06831506
learning rate: 0.0154303349962
Epoch:  41  avg train loss: 0.160488272836  Reg Loss: 4.14182315353e-06 total time: 14.458354234695435
avg loss validation: 0.143027858686 failed count: 0
learning rate: 0.0152498570333
Epoch:  42  avg train loss: 0.152779556813  Reg Loss: 4.15786148926e-06 total time: 31.07236385345459
avg loss validation: 0.155120576398 failed count: 1
learning rate: 0.0150755672289
Epoch:  43  avg train loss: 0.154049805393  Reg Loss: 4.17011778507e-06 total time: 45.889625787734985
avg loss validation: 0.205557816036 failed count: 2
learning rate: 0.01490711985
Epoch:  44  avg train loss: 0.149871712319  Reg Loss: 4.18286652345e-06 total time: 60.75620222091675
avg loss validation: 0.138454856659 failed count: 0
learning rate: 0.0147441956155
Epoch:  45  avg train loss: 0.151254550624  Reg Loss: 4.19342884381e-06 total time: 77.82764506340027
avg loss validation: 0.139569525605 failed count: 1
iter 0
100/1000
200/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
iter 2
100/1000
200/1000
iter 3
100/1000
200/1000
300/1000
400/1000
iter 4
100/1000
200/1000
300/1000
iter 5
100/1000
200/1000
300/1000
400/1000
iter 6
100/1000
200/1000
iter 7
100/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
iter 9
100/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 11
100/1000
200/1000
300/1000
400/1000
iter 12
100/1000
200/1000
300/1000
iter 13
100/1000
200/1000
300/1000
400/1000
iter 14
100/1000
200/1000
300/1000
400/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
iter 16
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 17
100/1000
200/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 19
100/1000
200/1000
returns [1500.1043641703088, 4183.7927229870711, 1560.2763333651146, 3578.6963406364303, 2619.8746679756982, 3254.7871001627309, 2237.4871537223653, 874.67457367462896, 4729.6681897863855, 1199.5257077041697, 7291.264575324446, 3642.6106536721973, 2985.9927696921827, 3658.1615399575558, 3338.034543899927, 4255.7616053598567, 8328.8935512585631, 1528.4711105350466, 6382.67664851881, 2236.2133778193893]
mean return 3469.34837651
std of return 1958.76422608
learning rate: 0.0145864991498
Epoch:  46  avg train loss: 0.150478375277  Reg Loss: 4.22327064343e-06 total time: 15.200284004211426
avg loss validation: 0.143811168898 failed count: 0
learning rate: 0.0144337567297
Epoch:  47  avg train loss: 0.141626998549  Reg Loss: 4.23419482455e-06 total time: 32.97097587585449
avg loss validation: 0.169626180648 failed count: 1
learning rate: 0.0142857142857
Epoch:  48  avg train loss: 0.143817846409  Reg Loss: 4.24110521111e-06 total time: 50.0902419090271
avg loss validation: 0.144076605228 failed count: 2
learning rate: 0.0141421356237
Epoch:  49  avg train loss: 0.141960258567  Reg Loss: 4.2488246363e-06 total time: 66.96093559265137
avg loss validation: 0.13724181808 failed count: 0
learning rate: 0.0140028008403
Epoch:  50  avg train loss: 0.138926509976  Reg Loss: 4.25628358445e-06 total time: 85.093665599823
avg loss validation: 0.133802592783 failed count: 0
iter 0
100/1000
200/1000
300/1000
400/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 2
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 3
100/1000
200/1000
300/1000
400/1000
iter 4
100/1000
200/1000
300/1000
iter 5
100/1000
200/1000
300/1000
400/1000
iter 6
100/1000
iter 7
100/1000
200/1000
iter 8
100/1000
200/1000
iter 9
100/1000
200/1000
300/1000
400/1000
iter 10
100/1000
200/1000
300/1000
400/1000
iter 11
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 12
100/1000
200/1000
300/1000
400/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
iter 14
100/1000
200/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 16
100/1000
200/1000
300/1000
iter 17
100/1000
200/1000
iter 18
100/1000
200/1000
iter 19
100/1000
200/1000
300/1000
returns [4306.5488289971481, 7238.5225452215282, 5866.6825088023979, 4112.7583797336256, 2931.1795580831827, 4319.6063578122794, 999.40234529470604, 2330.420935822759, 1649.6378664939109, 3841.5099227318183, 3949.161031816046, 7548.9661462646673, 3650.0589810967017, 8714.124907782174, 1850.0182763541225, 7352.9174268763136, 2855.9759260458068, 2017.2477803814952, 1714.7731078582487, 3134.4387129824518]
mean return 4019.19757732
std of return 2175.72958814
learning rate: 0.0138675049056
Epoch:  51  avg train loss: 0.144667338408  Reg Loss: 4.25897746023e-06 total time: 16.168346643447876
avg loss validation: 0.123652246408 failed count: 0
learning rate: 0.0137360563949
Epoch:  52  avg train loss: 0.139970480872  Reg Loss: 4.26854955634e-06 total time: 35.052793741226196
avg loss validation: 0.140295273246 failed count: 1
learning rate: 0.0136082763488
Epoch:  53  avg train loss: 0.13775647776  Reg Loss: 4.27462824134e-06 total time: 51.752936363220215
avg loss validation: 0.129399867471 failed count: 2
learning rate: 0.0134839972493
Epoch:  54  avg train loss: 0.134213707998  Reg Loss: 4.27937927228e-06 total time: 68.92755627632141
avg loss validation: 0.154175974523 failed count: 3
learning rate: 0.0133630620956
Epoch:  55  avg train loss: 0.136484121281  Reg Loss: 4.28403184986e-06 total time: 85.64412689208984
avg loss validation: 0.13318053915 failed count: 4
iter 0
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
iter 2
100/1000
iter 3
100/1000
200/1000
300/1000
iter 4
100/1000
200/1000
iter 5
100/1000
200/1000
300/1000
iter 6
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 7
100/1000
200/1000
300/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 9
100/1000
200/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
iter 11
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 12
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
iter 14
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 16
100/1000
200/1000
300/1000
iter 17
100/1000
200/1000
iter 18
iter 19
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
returns [6478.1979040568049, 4587.8775123268197, 773.91888700967036, 2635.1158415680889, 2429.9929769513096, 3241.0774576631329, 8886.7535008523591, 3078.9744150877814, 6632.0595760842507, 1999.3858462529895, 4948.8767443154147, 5615.0691023112413, 7011.8280906344407, 4624.2616380265817, 8697.0340157553528, 8948.6916723068534, 2533.6065725162084, 1543.4507006051454, 329.27010007025234, 8919.6939052365378]
mean return 4695.75682298
std of return 2767.30594791
learning rate: 0.0132453235707
Epoch:  56  avg train loss: 0.134674015849  Reg Loss: 4.36393370424e-06 total time: 17.234617948532104
avg loss validation: 0.138842448002 failed count: 0
learning rate: 0.013130643286
Epoch:  57  avg train loss: 0.131805916122  Reg Loss: 4.36871488572e-06 total time: 37.235820293426514
avg loss validation: 0.147379949031 failed count: 1
learning rate: 0.0130188910981
Epoch:  58  avg train loss: 0.129900554334  Reg Loss: 4.37234557723e-06 total time: 55.05355453491211
avg loss validation: 0.130234696734 failed count: 0
learning rate: 0.0129099444874
Epoch:  59  avg train loss: 0.128978213252  Reg Loss: 4.37648914281e-06 total time: 75.33768105506897
avg loss validation: 0.14357214224 failed count: 1
learning rate: 0.0128036879933
Epoch:  60  avg train loss: 0.125710690328  Reg Loss: 4.37823463265e-06 total time: 93.15665173530579
avg loss validation: 0.115465563436 failed count: 0
iter 0
100/1000
iter 1
100/1000
200/1000
iter 2
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 3
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
iter 4
100/1000
200/1000
300/1000
400/1000
iter 5
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 6
100/1000
200/1000
300/1000
400/1000
500/1000
iter 7
100/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 9
100/1000
200/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
iter 11
100/1000
200/1000
iter 12
100/1000
200/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
iter 14
100/1000
200/1000
300/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
iter 16
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 17
100/1000
200/1000
300/1000
400/1000
500/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 19
100/1000
200/1000
returns [853.48765219477991, 1582.4555245173467, 9033.0763990560972, 9139.0665883476595, 3808.5157608495192, 9142.6703278269943, 4900.3062636321547, 788.41013436895378, 5740.5926778653129, 2391.82610906741, 8528.8040824137188, 1483.6068724830716, 1552.3554218787785, 4814.0069145580555, 3419.1009308268103, 9039.1760575411936, 6576.1400600322077, 4628.9497114579754, 6606.861872157895, 1693.7905139300869]
mean return 4786.15999375
std of return 2972.57012287
learning rate: 0.0127000127
Epoch:  61  avg train loss: 0.127218930586  Reg Loss: 4.33928239399e-06 total time: 18.275684595108032
avg loss validation: 0.114767740776 failed count: 0
learning rate: 0.012598815767
Epoch:  62  avg train loss: 0.12714321972  Reg Loss: 4.34155026312e-06 total time: 40.03924369812012
avg loss validation: 0.134932931547 failed count: 1
learning rate: 0.0125
Epoch:  63  avg train loss: 0.124396434009  Reg Loss: 4.34464365721e-06 total time: 59.50920581817627
avg loss validation: 0.122753524763 failed count: 2
learning rate: 0.0124034734589
Epoch:  64  avg train loss: 0.121122593788  Reg Loss: 4.34562511278e-06 total time: 79.25662684440613
avg loss validation: 0.129939761467 failed count: 3
learning rate: 0.0123091490979
Epoch:  65  avg train loss: 0.120761319013  Reg Loss: 4.34494290368e-06 total time: 99.60034084320068
avg loss validation: 0.113602543596 failed count: 0
iter 0
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 2
100/1000
200/1000
iter 3
100/1000
200/1000
300/1000
400/1000
iter 4
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 5
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 6
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 7
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
iter 9
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 11
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 12
100/1000
200/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 14
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 16
100/1000
iter 17
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 19
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
returns [8678.8461574195408, 6439.858055292164, 1834.7481841976769, 4245.0905887472418, 8959.7846298320947, 8953.6418027923755, 9134.4949010099153, 9210.0826576353666, 8235.378300276032, 7928.4541434144157, 8812.1363477854338, 8971.2680576013609, 1569.2869213096228, 9169.758336556597, 8839.1831985820209, 9036.9891105234019, 1292.5320150288094, 9036.5209033803349, 9010.8331926614883, 6934.5750019491898]
mean return 7314.6731253
std of return 2688.67936501
learning rate: 0.0122169444356
Epoch:  66  avg train loss: 0.122586205743  Reg Loss: 4.38956108766e-06 total time: 20.278513193130493
avg loss validation: 0.112860407316 failed count: 0
learning rate: 0.0121267812518
