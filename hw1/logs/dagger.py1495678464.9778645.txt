3.6.0 |Anaconda custom (64-bit)| (default, Dec 23 2016, 12:22:00) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]
loading and building expert policy
obs (1, 376) (1, 376)
loaded and built
iter 0
iter 1
iter 2
iter 3
iter 4
iter 5
iter 6
iter 7
iter 8
iter 9
iter 10
iter 11
iter 12
iter 13
iter 14
iter 15
iter 16
iter 17
iter 18
iter 19
returns [81.224484459695049, 81.14863958036706, 81.522740171157423, 76.360535824632336, 86.257860380305303, 81.320618557053393, 81.168477116761309, 81.453003038144914, 86.18977872072, 81.297169367304306, 86.294504370649406, 81.143592397018224, 81.118163162447843, 76.613072536071869, 81.109337170769891, 81.537170673692131, 81.226523173908035, 81.153422532867467, 80.121193172756477, 81.247623596744532]
mean return 81.4753955002
std of return 2.45839808707
learning rate: 0.0707106781187
Epoch:  1  avg train loss: 2.52812172067  Reg Loss: 9.67249411462e-07 total time: 11.359203815460205
avg loss validation: 0.640842027809 failed count: 0
learning rate: 0.057735026919
Epoch:  2  avg train loss: 0.552224632217  Reg Loss: 1.21627217425e-06 total time: 25.017876863479614
avg loss validation: 0.466531093845 failed count: 0
learning rate: 0.05
Epoch:  3  avg train loss: 0.448186201622  Reg Loss: 1.49561922477e-06 total time: 38.276036500930786
avg loss validation: 0.417180467177 failed count: 0
learning rate: 0.04472135955
Epoch:  4  avg train loss: 0.392506021238  Reg Loss: 1.75565000874e-06 total time: 51.51406216621399
avg loss validation: 0.373125997152 failed count: 0
learning rate: 0.0408248290464
Epoch:  5  avg train loss: 0.362700666699  Reg Loss: 1.97781380845e-06 total time: 65.15917301177979
avg loss validation: 0.460448035997 failed count: 1
iter 0
iter 1
iter 2
iter 3
iter 4
iter 5
iter 6
iter 7
iter 8
iter 9
iter 10
iter 11
iter 12
iter 13
iter 14
iter 15
iter 16
iter 17
iter 18
iter 19
returns [233.30394084428545, 231.50426242129464, 212.90424555007405, 224.14595277067997, 259.06233902047296, 220.64631866832852, 234.59130097232207, 237.61643961134405, 215.820950383764, 244.03676551089899, 243.52999232008824, 242.00457906457797, 259.09885933129419, 236.00242629787317, 234.61842779963024, 229.03181693846449, 202.63400580892196, 227.92312954404665, 233.70063041805767, 209.03612806243507]
mean return 231.560625567
std of return 14.3855483606
learning rate: 0.0377964473009
Epoch:  6  avg train loss: 0.342662833166  Reg Loss: 2.15721333138e-06 total time: 11.185813426971436
avg loss validation: 0.299681925114 failed count: 0
learning rate: 0.0353553390593
Epoch:  7  avg train loss: 0.299997791422  Reg Loss: 2.32224615085e-06 total time: 24.97679829597473
avg loss validation: 0.420643710301 failed count: 1
learning rate: 0.0333333333333
Epoch:  8  avg train loss: 0.298964756247  Reg Loss: 2.46718384249e-06 total time: 36.52137851715088
avg loss validation: 0.325456295115 failed count: 2
learning rate: 0.0316227766017
Epoch:  9  avg train loss: 0.279635912144  Reg Loss: 2.59221919798e-06 total time: 48.27566599845886
avg loss validation: 0.265963383355 failed count: 0
learning rate: 0.0301511344578
Epoch:  10  avg train loss: 0.259296071297  Reg Loss: 2.70636204096e-06 total time: 61.572190046310425
avg loss validation: 0.252251612487 failed count: 0
iter 0
iter 1
100/1000
iter 2
100/1000
iter 3
iter 4
100/1000
200/1000
iter 5
100/1000
iter 6
100/1000
iter 7
100/1000
iter 8
100/1000
iter 9
100/1000
iter 10
100/1000
iter 11
100/1000
iter 12
100/1000
iter 13
100/1000
iter 14
100/1000
iter 15
iter 16
100/1000
iter 17
iter 18
100/1000
iter 19
100/1000
returns [530.5345744715828, 903.86179513943728, 867.1798873909446, 578.03799954663407, 1267.3936079901325, 695.69592033350023, 802.39310867697839, 961.88518429530814, 618.25960230480882, 765.52882841811345, 649.6696010270349, 617.69074774316346, 946.57301205424733, 1069.1766915956848, 802.46423209847376, 452.57290915251491, 1041.802233655912, 529.77696549212624, 646.78077190484532, 767.60031085466915]
mean return 775.743899207
std of return 205.143907249
learning rate: 0.0288675134595
Epoch:  11  avg train loss: 0.278890509989  Reg Loss: 2.86597897869e-06 total time: 11.453579902648926
avg loss validation: 0.263339402195 failed count: 0
learning rate: 0.0277350098113
Epoch:  12  avg train loss: 0.247721349167  Reg Loss: 2.97932427763e-06 total time: 25.456716299057007
avg loss validation: 0.243701511467 failed count: 0
learning rate: 0.0267261241912
Epoch:  13  avg train loss: 0.244423973237  Reg Loss: 3.07141284999e-06 total time: 39.03401780128479
avg loss validation: 0.275414149875 failed count: 1
learning rate: 0.0258198889747
Epoch:  14  avg train loss: 0.236306612969  Reg Loss: 3.15745347626e-06 total time: 50.87952518463135
avg loss validation: 0.23557643391 failed count: 0
learning rate: 0.025
Epoch:  15  avg train loss: 0.23286267299  Reg Loss: 3.23683329374e-06 total time: 64.94643259048462
avg loss validation: 0.213435619557 failed count: 0
iter 0
100/1000
iter 1
100/1000
iter 2
100/1000
iter 3
100/1000
200/1000
iter 4
100/1000
200/1000
iter 5
100/1000
iter 6
100/1000
200/1000
iter 7
iter 8
100/1000
iter 9
100/1000
iter 10
100/1000
200/1000
iter 11
100/1000
iter 12
100/1000
iter 13
100/1000
200/1000
iter 14
100/1000
200/1000
300/1000
iter 15
100/1000
iter 16
100/1000
iter 17
100/1000
iter 18
100/1000
iter 19
100/1000
returns [1141.957495049355, 746.94724032488216, 1216.6706033247765, 1690.8627532569853, 1385.3360873314441, 1081.6388488379753, 1964.922783953529, 580.86157671732769, 1248.91935836827, 966.80019577477026, 1537.3059498845571, 1196.1930318897655, 881.1055177579658, 1485.2349291343962, 2265.5479379511762, 978.63597830806316, 1206.0347639671913, 800.30212427367087, 1323.771348202368, 1334.6429594399779]
mean return 1251.68457419
std of return 396.514633342
learning rate: 0.0242535625036
Epoch:  16  avg train loss: 0.228568067136  Reg Loss: 3.20866831968e-06 total time: 11.820615768432617
avg loss validation: 0.21847011292 failed count: 0
learning rate: 0.0235702260396
Epoch:  17  avg train loss: 0.220928331321  Reg Loss: 3.27677941842e-06 total time: 26.276345252990723
avg loss validation: 0.210152822812 failed count: 0
learning rate: 0.0229415733871
Epoch:  18  avg train loss: 0.215199501179  Reg Loss: 3.33761318432e-06 total time: 40.69077157974243
avg loss validation: 0.216828881997 failed count: 1
learning rate: 0.022360679775
Epoch:  19  avg train loss: 0.21216917543  Reg Loss: 3.39579402517e-06 total time: 52.92118954658508
avg loss validation: 0.197262273943 failed count: 0
learning rate: 0.0218217890236
Epoch:  20  avg train loss: 0.202102038031  Reg Loss: 3.44866353028e-06 total time: 67.20165467262268
avg loss validation: 0.217005700699 failed count: 1
iter 0
100/1000
iter 1
100/1000
iter 2
100/1000
200/1000
iter 3
100/1000
iter 4
100/1000
iter 5
100/1000
200/1000
iter 6
100/1000
iter 7
100/1000
200/1000
iter 8
100/1000
iter 9
100/1000
iter 10
100/1000
200/1000
300/1000
iter 11
100/1000
iter 12
100/1000
iter 13
100/1000
iter 14
100/1000
iter 15
100/1000
iter 16
100/1000
iter 17
100/1000
iter 18
100/1000
iter 19
100/1000
returns [1260.160916135746, 863.13070987006449, 1680.8543529175022, 879.47751930991024, 883.7051012276454, 1439.4907579194457, 1048.9333297998437, 1784.0064494344522, 761.06000274992891, 1042.6356758033598, 2515.6204644937247, 1047.086617503928, 606.93739136758791, 881.2620245438776, 669.09497176282468, 958.33512180188416, 1081.999825520988, 1203.6867342841499, 1130.547779187498, 1165.483272463327]
mean return 1145.1754509
std of return 429.966718753
learning rate: 0.0213200716356
Epoch:  21  avg train loss: 0.212242859031  Reg Loss: 3.53709925927e-06 total time: 12.51911973953247
avg loss validation: 0.203545736797 failed count: 0
learning rate: 0.0208514414057
Epoch:  22  avg train loss: 0.196957164492  Reg Loss: 3.59306031169e-06 total time: 26.816561460494995
avg loss validation: 0.247323076159 failed count: 1
learning rate: 0.0204124145232
Epoch:  23  avg train loss: 0.199882054306  Reg Loss: 3.64183645061e-06 total time: 39.369361877441406
avg loss validation: 0.186126879113 failed count: 0
learning rate: 0.02
Epoch:  24  avg train loss: 0.192947469973  Reg Loss: 3.68230697745e-06 total time: 54.12714743614197
avg loss validation: 0.201798314286 failed count: 1
learning rate: 0.0196116135138
Epoch:  25  avg train loss: 0.18955433941  Reg Loss: 3.7236692701e-06 total time: 66.75538158416748
avg loss validation: 0.231667653264 failed count: 2
iter 0
100/1000
200/1000
iter 1
100/1000
iter 2
100/1000
iter 3
100/1000
iter 4
100/1000
iter 5
100/1000
200/1000
300/1000
iter 6
100/1000
iter 7
100/1000
iter 8
iter 9
100/1000
iter 10
100/1000
iter 11
100/1000
200/1000
iter 12
100/1000
iter 13
iter 14
iter 15
100/1000
iter 16
100/1000
iter 17
100/1000
iter 18
100/1000
200/1000
iter 19
returns [1748.1172530799142, 1251.284491129702, 640.72042624563767, 1058.8519365237862, 1218.3059877035951, 2419.9862576895225, 809.33364753827777, 925.73987569651263, 447.80765235950781, 726.82721224396494, 790.82821439466068, 1874.0127123107718, 796.68611539728738, 443.82929461751399, 536.4425885185932, 846.33475736457535, 1127.3987640873972, 1269.3004293291697, 2197.7434307405906, 401.42799146159865]
mean return 1076.54895192
std of return 565.775714006
learning rate: 0.019245008973
Epoch:  26  avg train loss: 0.190521398539  Reg Loss: 3.80891789828e-06 total time: 12.891714096069336
avg loss validation: 0.175354081701 failed count: 0
learning rate: 0.0188982236505
Epoch:  27  avg train loss: 0.186149991875  Reg Loss: 3.84775548815e-06 total time: 28.01975655555725
avg loss validation: 0.197999629152 failed count: 1
learning rate: 0.0185695338177
Epoch:  28  avg train loss: 0.179379705467  Reg Loss: 3.88359504997e-06 total time: 40.8999285697937
avg loss validation: 0.171898862834 failed count: 0
learning rate: 0.0182574185835
Epoch:  29  avg train loss: 0.180139463375  Reg Loss: 3.91421437606e-06 total time: 55.533940076828
avg loss validation: 0.18235453341 failed count: 1
learning rate: 0.0179605302027
Epoch:  30  avg train loss: 0.171582153944  Reg Loss: 3.94457954237e-06 total time: 68.43747186660767
avg loss validation: 0.156300897682 failed count: 0
iter 0
100/1000
200/1000
iter 1
100/1000
iter 2
100/1000
200/1000
300/1000
400/1000
iter 3
100/1000
iter 4
100/1000
200/1000
300/1000
400/1000
500/1000
iter 5
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 6
100/1000
200/1000
300/1000
iter 7
100/1000
iter 8
100/1000
200/1000
iter 9
100/1000
200/1000
iter 10
100/1000
200/1000
iter 11
100/1000
200/1000
300/1000
iter 12
100/1000
200/1000
300/1000
iter 13
100/1000
200/1000
iter 14
100/1000
iter 15
100/1000
iter 16
100/1000
iter 17
100/1000
iter 18
100/1000
200/1000
iter 19
100/1000
returns [1904.265416948849, 968.8300420598066, 3199.2770159131378, 1440.658916788999, 4072.8825725178731, 5963.9996373091335, 3021.8209960099348, 1054.1252798693235, 1568.4818961414383, 2154.7379167036806, 2154.5151135548899, 2207.535749212946, 2460.958811814337, 1828.7328882360532, 959.09871488209797, 704.74835734475232, 1200.613500924308, 711.60602247108693, 1786.179195207761, 1231.737975248948]
mean return 2029.74030096
std of return 1244.38410986
learning rate: 0.0176776695297
Epoch:  31  avg train loss: 0.185733863608  Reg Loss: 3.94180232438e-06 total time: 13.003581285476685
avg loss validation: 0.167251649452 failed count: 0
learning rate: 0.0174077655956
Epoch:  32  avg train loss: 0.167984204213  Reg Loss: 3.97360980366e-06 total time: 28.64993119239807
avg loss validation: 0.175806737165 failed count: 1
learning rate: 0.0171498585143
Epoch:  33  avg train loss: 0.167786263689  Reg Loss: 3.99445593306e-06 total time: 42.100648164749146
avg loss validation: 0.153351069629 failed count: 0
learning rate: 0.0169030850946
Epoch:  34  avg train loss: 0.166579542395  Reg Loss: 4.01376847114e-06 total time: 57.33456611633301
avg loss validation: 0.178507917698 failed count: 1
learning rate: 0.0166666666667
Epoch:  35  avg train loss: 0.165769378957  Reg Loss: 4.03426029589e-06 total time: 70.77266597747803
avg loss validation: 0.151632638979 failed count: 0
iter 0
100/1000
iter 1
100/1000
iter 2
100/1000
200/1000
300/1000
iter 3
100/1000
200/1000
300/1000
400/1000
iter 4
100/1000
200/1000
300/1000
iter 5
100/1000
200/1000
300/1000
400/1000
iter 6
100/1000
iter 7
100/1000
200/1000
300/1000
400/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
iter 9
100/1000
iter 10
100/1000
iter 11
100/1000
iter 12
100/1000
iter 13
100/1000
200/1000
iter 14
100/1000
200/1000
iter 15
100/1000
iter 16
100/1000
iter 17
100/1000
200/1000
300/1000
iter 18
iter 19
100/1000
returns [979.95371344467958, 936.26786085911783, 2480.6114609756187, 3191.4723756231697, 2988.8817232400897, 3393.0488690869311, 993.55383019442797, 3158.5610752058183, 4451.3257917078281, 721.43785290824815, 830.37899338964996, 1301.9545584421219, 1035.0073783133932, 1551.9330271941983, 1479.1288098261789, 1313.5059940042656, 825.59441971344711, 2495.8219125911437, 532.26584175806568, 1131.6469789117325]
mean return 1789.61762337
std of return 1098.13417361
learning rate: 0.0164398987305
Epoch:  36  avg train loss: 0.162474335593  Reg Loss: 4.04553227918e-06 total time: 13.572719097137451
avg loss validation: 0.166583085204 failed count: 0
learning rate: 0.0162221421131
Epoch:  37  avg train loss: 0.161119991713  Reg Loss: 4.06330101522e-06 total time: 29.975618600845337
avg loss validation: 0.158718028068 failed count: 0
learning rate: 0.0160128153805
Epoch:  38  avg train loss: 0.160515717042  Reg Loss: 4.08090700861e-06 total time: 46.4853618144989
avg loss validation: 0.143920038429 failed count: 0
learning rate: 0.0158113883008
Epoch:  39  avg train loss: 0.156278566807  Reg Loss: 4.09860080783e-06 total time: 62.17877221107483
avg loss validation: 0.154394479045 failed count: 1
learning rate: 0.0156173761889
Epoch:  40  avg train loss: 0.152294728024  Reg Loss: 4.11126453283e-06 total time: 76.11611914634705
avg loss validation: 0.141728423673 failed count: 0
iter 0
100/1000
200/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 2
100/1000
200/1000
iter 3
100/1000
200/1000
300/1000
iter 4
100/1000
200/1000
300/1000
iter 5
100/1000
200/1000
300/1000
400/1000
iter 6
100/1000
200/1000
iter 7
100/1000
200/1000
iter 8
100/1000
200/1000
300/1000
400/1000
iter 9
100/1000
200/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 11
100/1000
200/1000
300/1000
iter 12
100/1000
200/1000
300/1000
400/1000
500/1000
iter 13
100/1000
200/1000
iter 14
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 15
100/1000
200/1000
300/1000
400/1000
iter 16
100/1000
iter 17
100/1000
200/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 19
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
returns [1463.5637276541609, 7076.2694109831828, 2016.3095930318516, 2917.5937185265998, 2451.2757922492542, 3601.7840923450167, 1932.7820514734619, 1784.6074618190792, 3364.9015429345168, 1967.6787065839742, 5436.2393736370104, 3025.2751886258584, 4359.0933823298774, 1837.2287577867628, 6632.0166569378234, 3796.8713977434259, 1043.9792841307283, 2153.5405844280544, 5669.5016540285887, 5934.2588913976087]
mean return 3423.23856343
std of return 1790.06831506
learning rate: 0.0154303349962
Epoch:  41  avg train loss: 0.160488272836  Reg Loss: 4.14182315353e-06 total time: 14.458354234695435
avg loss validation: 0.143027858686 failed count: 0
learning rate: 0.0152498570333
Epoch:  42  avg train loss: 0.152779556813  Reg Loss: 4.15786148926e-06 total time: 31.07236385345459
avg loss validation: 0.155120576398 failed count: 1
learning rate: 0.0150755672289
Epoch:  43  avg train loss: 0.154049805393  Reg Loss: 4.17011778507e-06 total time: 45.889625787734985
avg loss validation: 0.205557816036 failed count: 2
learning rate: 0.01490711985
Epoch:  44  avg train loss: 0.149871712319  Reg Loss: 4.18286652345e-06 total time: 60.75620222091675
avg loss validation: 0.138454856659 failed count: 0
learning rate: 0.0147441956155
Epoch:  45  avg train loss: 0.151254550624  Reg Loss: 4.19342884381e-06 total time: 77.82764506340027
avg loss validation: 0.139569525605 failed count: 1
iter 0
100/1000
200/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
iter 2
100/1000
200/1000
iter 3
100/1000
200/1000
300/1000
400/1000
iter 4
100/1000
200/1000
300/1000
iter 5
100/1000
200/1000
300/1000
400/1000
iter 6
100/1000
200/1000
iter 7
100/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
iter 9
100/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 11
100/1000
200/1000
300/1000
400/1000
iter 12
100/1000
200/1000
300/1000
iter 13
100/1000
200/1000
300/1000
400/1000
iter 14
100/1000
200/1000
300/1000
400/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
iter 16
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 17
100/1000
200/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 19
100/1000
200/1000
returns [1500.1043641703088, 4183.7927229870711, 1560.2763333651146, 3578.6963406364303, 2619.8746679756982, 3254.7871001627309, 2237.4871537223653, 874.67457367462896, 4729.6681897863855, 1199.5257077041697, 7291.264575324446, 3642.6106536721973, 2985.9927696921827, 3658.1615399575558, 3338.034543899927, 4255.7616053598567, 8328.8935512585631, 1528.4711105350466, 6382.67664851881, 2236.2133778193893]
mean return 3469.34837651
std of return 1958.76422608
learning rate: 0.0145864991498
Epoch:  46  avg train loss: 0.150478375277  Reg Loss: 4.22327064343e-06 total time: 15.200284004211426
avg loss validation: 0.143811168898 failed count: 0
learning rate: 0.0144337567297
Epoch:  47  avg train loss: 0.141626998549  Reg Loss: 4.23419482455e-06 total time: 32.97097587585449
avg loss validation: 0.169626180648 failed count: 1
learning rate: 0.0142857142857
Epoch:  48  avg train loss: 0.143817846409  Reg Loss: 4.24110521111e-06 total time: 50.0902419090271
avg loss validation: 0.144076605228 failed count: 2
learning rate: 0.0141421356237
Epoch:  49  avg train loss: 0.141960258567  Reg Loss: 4.2488246363e-06 total time: 66.96093559265137
avg loss validation: 0.13724181808 failed count: 0
learning rate: 0.0140028008403
Epoch:  50  avg train loss: 0.138926509976  Reg Loss: 4.25628358445e-06 total time: 85.093665599823
avg loss validation: 0.133802592783 failed count: 0
iter 0
100/1000
200/1000
300/1000
400/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 2
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 3
100/1000
200/1000
300/1000
400/1000
iter 4
100/1000
200/1000
300/1000
iter 5
100/1000
200/1000
300/1000
400/1000
iter 6
100/1000
iter 7
100/1000
200/1000
iter 8
100/1000
200/1000
iter 9
100/1000
200/1000
300/1000
400/1000
iter 10
100/1000
200/1000
300/1000
400/1000
iter 11
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 12
100/1000
200/1000
300/1000
400/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
iter 14
100/1000
200/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 16
100/1000
200/1000
300/1000
iter 17
100/1000
200/1000
iter 18
100/1000
200/1000
iter 19
100/1000
200/1000
300/1000
returns [4306.5488289971481, 7238.5225452215282, 5866.6825088023979, 4112.7583797336256, 2931.1795580831827, 4319.6063578122794, 999.40234529470604, 2330.420935822759, 1649.6378664939109, 3841.5099227318183, 3949.161031816046, 7548.9661462646673, 3650.0589810967017, 8714.124907782174, 1850.0182763541225, 7352.9174268763136, 2855.9759260458068, 2017.2477803814952, 1714.7731078582487, 3134.4387129824518]
mean return 4019.19757732
std of return 2175.72958814
learning rate: 0.0138675049056
Epoch:  51  avg train loss: 0.144667338408  Reg Loss: 4.25897746023e-06 total time: 16.168346643447876
avg loss validation: 0.123652246408 failed count: 0
learning rate: 0.0137360563949
Epoch:  52  avg train loss: 0.139970480872  Reg Loss: 4.26854955634e-06 total time: 35.052793741226196
avg loss validation: 0.140295273246 failed count: 1
learning rate: 0.0136082763488
Epoch:  53  avg train loss: 0.13775647776  Reg Loss: 4.27462824134e-06 total time: 51.752936363220215
avg loss validation: 0.129399867471 failed count: 2
learning rate: 0.0134839972493
Epoch:  54  avg train loss: 0.134213707998  Reg Loss: 4.27937927228e-06 total time: 68.92755627632141
avg loss validation: 0.154175974523 failed count: 3
learning rate: 0.0133630620956
Epoch:  55  avg train loss: 0.136484121281  Reg Loss: 4.28403184986e-06 total time: 85.64412689208984
avg loss validation: 0.13318053915 failed count: 4
iter 0
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
iter 2
100/1000
iter 3
100/1000
200/1000
300/1000
iter 4
100/1000
200/1000
iter 5
100/1000
200/1000
300/1000
iter 6
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 7
100/1000
200/1000
300/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 9
100/1000
200/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
iter 11
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 12
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
iter 14
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 16
100/1000
200/1000
300/1000
iter 17
100/1000
200/1000
iter 18
iter 19
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
returns [6478.1979040568049, 4587.8775123268197, 773.91888700967036, 2635.1158415680889, 2429.9929769513096, 3241.0774576631329, 8886.7535008523591, 3078.9744150877814, 6632.0595760842507, 1999.3858462529895, 4948.8767443154147, 5615.0691023112413, 7011.8280906344407, 4624.2616380265817, 8697.0340157553528, 8948.6916723068534, 2533.6065725162084, 1543.4507006051454, 329.27010007025234, 8919.6939052365378]
mean return 4695.75682298
std of return 2767.30594791
learning rate: 0.0132453235707
Epoch:  56  avg train loss: 0.134674015849  Reg Loss: 4.36393370424e-06 total time: 17.234617948532104
avg loss validation: 0.138842448002 failed count: 0
learning rate: 0.013130643286
Epoch:  57  avg train loss: 0.131805916122  Reg Loss: 4.36871488572e-06 total time: 37.235820293426514
avg loss validation: 0.147379949031 failed count: 1
learning rate: 0.0130188910981
Epoch:  58  avg train loss: 0.129900554334  Reg Loss: 4.37234557723e-06 total time: 55.05355453491211
avg loss validation: 0.130234696734 failed count: 0
learning rate: 0.0129099444874
Epoch:  59  avg train loss: 0.128978213252  Reg Loss: 4.37648914281e-06 total time: 75.33768105506897
avg loss validation: 0.14357214224 failed count: 1
learning rate: 0.0128036879933
Epoch:  60  avg train loss: 0.125710690328  Reg Loss: 4.37823463265e-06 total time: 93.15665173530579
avg loss validation: 0.115465563436 failed count: 0
iter 0
100/1000
iter 1
100/1000
200/1000
iter 2
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 3
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
iter 4
100/1000
200/1000
300/1000
400/1000
iter 5
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 6
100/1000
200/1000
300/1000
400/1000
500/1000
iter 7
100/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 9
100/1000
200/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
iter 11
100/1000
200/1000
iter 12
100/1000
200/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
iter 14
100/1000
200/1000
300/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
iter 16
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 17
100/1000
200/1000
300/1000
400/1000
500/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 19
100/1000
200/1000
returns [853.48765219477991, 1582.4555245173467, 9033.0763990560972, 9139.0665883476595, 3808.5157608495192, 9142.6703278269943, 4900.3062636321547, 788.41013436895378, 5740.5926778653129, 2391.82610906741, 8528.8040824137188, 1483.6068724830716, 1552.3554218787785, 4814.0069145580555, 3419.1009308268103, 9039.1760575411936, 6576.1400600322077, 4628.9497114579754, 6606.861872157895, 1693.7905139300869]
mean return 4786.15999375
std of return 2972.57012287
learning rate: 0.0127000127
Epoch:  61  avg train loss: 0.127218930586  Reg Loss: 4.33928239399e-06 total time: 18.275684595108032
avg loss validation: 0.114767740776 failed count: 0
learning rate: 0.012598815767
Epoch:  62  avg train loss: 0.12714321972  Reg Loss: 4.34155026312e-06 total time: 40.03924369812012
avg loss validation: 0.134932931547 failed count: 1
learning rate: 0.0125
Epoch:  63  avg train loss: 0.124396434009  Reg Loss: 4.34464365721e-06 total time: 59.50920581817627
avg loss validation: 0.122753524763 failed count: 2
learning rate: 0.0124034734589
Epoch:  64  avg train loss: 0.121122593788  Reg Loss: 4.34562511278e-06 total time: 79.25662684440613
avg loss validation: 0.129939761467 failed count: 3
learning rate: 0.0123091490979
Epoch:  65  avg train loss: 0.120761319013  Reg Loss: 4.34494290368e-06 total time: 99.60034084320068
avg loss validation: 0.113602543596 failed count: 0
iter 0
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 2
100/1000
200/1000
iter 3
100/1000
200/1000
300/1000
400/1000
iter 4
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 5
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 6
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 7
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
iter 9
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 11
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 12
100/1000
200/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 14
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 16
100/1000
iter 17
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 19
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
returns [8678.8461574195408, 6439.858055292164, 1834.7481841976769, 4245.0905887472418, 8959.7846298320947, 8953.6418027923755, 9134.4949010099153, 9210.0826576353666, 8235.378300276032, 7928.4541434144157, 8812.1363477854338, 8971.2680576013609, 1569.2869213096228, 9169.758336556597, 8839.1831985820209, 9036.9891105234019, 1292.5320150288094, 9036.5209033803349, 9010.8331926614883, 6934.5750019491898]
mean return 7314.6731253
std of return 2688.67936501
learning rate: 0.0122169444356
Epoch:  66  avg train loss: 0.122586205743  Reg Loss: 4.38956108766e-06 total time: 20.278513193130493
avg loss validation: 0.112860407316 failed count: 0
learning rate: 0.0121267812518
Epoch:  67  avg train loss: 0.120031032082  Reg Loss: 4.39035923142e-06 total time: 43.500417709350586
avg loss validation: 0.114801735083 failed count: 1
learning rate: 0.0120385853086
Epoch:  68  avg train loss: 0.118588266684  Reg Loss: 4.39063090545e-06 total time: 64.60717129707336
avg loss validation: 0.115863534644 failed count: 2
learning rate: 0.0119522860933
Epoch:  69  avg train loss: 0.115724188048  Reg Loss: 4.39078947918e-06 total time: 85.66092777252197
avg loss validation: 0.113599008069 failed count: 3
learning rate: 0.0118678165819
Epoch:  70  avg train loss: 0.114893272059  Reg Loss: 4.38915668903e-06 total time: 106.57479953765869
avg loss validation: 0.138278548372 failed count: 4
iter 0
100/1000
iter 1
100/1000
200/1000
300/1000
iter 2
100/1000
iter 3
100/1000
200/1000
iter 4
100/1000
200/1000
300/1000
400/1000
500/1000
iter 5
100/1000
200/1000
iter 6
100/1000
200/1000
300/1000
400/1000
iter 7
100/1000
200/1000
300/1000
400/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 9
100/1000
200/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
iter 11
100/1000
iter 12
100/1000
iter 13
100/1000
iter 14
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 15
100/1000
200/1000
300/1000
400/1000
iter 16
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 17
100/1000
200/1000
iter 18
100/1000
iter 19
100/1000
200/1000
returns [756.24416861368343, 2350.8300765006447, 1271.8573850126184, 1839.0444594369944, 4236.2508693548789, 1376.7052141208444, 3071.4706254243815, 3257.1732889385121, 5080.0204857988219, 1586.3949222299311, 4455.5222947998791, 723.39708535155762, 707.58133585711528, 579.37132573586871, 7759.4824371878331, 3148.8654455576248, 6310.3819020199408, 1562.289217534634, 751.03818471817158, 2068.7825121330366]
mean return 2644.63516182
std of return 1973.13770874
learning rate: 0.0117851130198
Epoch:  71  avg train loss: 0.116268889721  Reg Loss: 4.33146945454e-06 total time: 20.683953285217285
avg loss validation: 0.105336069342 failed count: 0
learning rate: 0.0117041147196
Epoch:  72  avg train loss: 0.116655473063  Reg Loss: 4.33033367223e-06 total time: 43.792606830596924
avg loss validation: 0.115718887776 failed count: 1
learning rate: 0.0116247638744
Epoch:  73  avg train loss: 0.112221945434  Reg Loss: 4.33046961348e-06 total time: 65.07628607749939
avg loss validation: 0.118565860228 failed count: 2
learning rate: 0.0115470053838
Epoch:  74  avg train loss: 0.112577160089  Reg Loss: 4.32892128577e-06 total time: 86.95634579658508
avg loss validation: 0.106150596432 failed count: 3
learning rate: 0.0114707866935
Epoch:  75  avg train loss: 0.11052965029  Reg Loss: 4.32759911841e-06 total time: 108.32086324691772
avg loss validation: 0.100936268866 failed count: 0
iter 0
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 2
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 3
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 4
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 5
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 6
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 7
100/1000
iter 8
100/1000
200/1000
300/1000
400/1000
iter 9
100/1000
200/1000
300/1000
400/1000
500/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 11
100/1000
200/1000
300/1000
iter 12
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 14
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
iter 16
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 17
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
iter 19
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
returns [9357.6757723389146, 9122.4802438038423, 9165.8893770802679, 9358.4267552535021, 9104.8451293551971, 6515.2948753891751, 9210.9335923764975, 797.43380851524296, 3375.0903325630666, 4716.1439209715209, 9182.0091806654546, 3120.8093613656479, 9052.8475392045148, 9070.4068549816147, 9151.6094192304827, 5354.550610758537, 9372.7325839869045, 8708.6883420110244, 5439.7425521703935, 7392.2656629646353]
mean return 7328.49379575
std of return 2562.46671029
learning rate: 0.011396057646
Epoch:  76  avg train loss: 0.111654533644  Reg Loss: 4.37002890691e-06 total time: 22.242191791534424
avg loss validation: 0.101021309108 failed count: 0
learning rate: 0.0113227703414
Epoch:  77  avg train loss: 0.10787262424  Reg Loss: 4.36811225905e-06 total time: 47.57222628593445
avg loss validation: 0.11960669653 failed count: 1
learning rate: 0.0112508790093
Epoch:  78  avg train loss: 0.109158085554  Reg Loss: 4.36571008591e-06 total time: 70.56262373924255
avg loss validation: 0.110697967922 failed count: 2
learning rate: 0.0111803398875
Epoch:  79  avg train loss: 0.10764581311  Reg Loss: 4.36278712815e-06 total time: 93.54317951202393
avg loss validation: 0.110529088904 failed count: 3
learning rate: 0.0111111111111
Epoch:  80  avg train loss: 0.106096502186  Reg Loss: 4.35897094916e-06 total time: 116.80583643913269
avg loss validation: 0.0983874242154 failed count: 0
iter 0
100/1000
200/1000
300/1000
400/1000
500/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 2
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 3
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
iter 4
100/1000
200/1000
300/1000
iter 5
100/1000
200/1000
iter 6
100/1000
iter 7
100/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 9
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
iter 11
100/1000
iter 12
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 14
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 15
100/1000
200/1000
300/1000
iter 16
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 17
100/1000
200/1000
300/1000
400/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 19
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
returns [4965.4826753853613, 9638.9495955520579, 7075.5513607799394, 8749.7388214847651, 3117.0430421809174, 1793.354460192518, 1454.0264902443216, 1019.7592201027084, 6233.8992455086109, 8457.036196774181, 5094.2116255034953, 1403.6638482770618, 9525.8844431371181, 6426.8189458807683, 9244.4088904851651, 2627.3710818870659, 9278.0702816248977, 4479.8309296115776, 7908.7198723413185, 9172.171129778133]
mean return 5883.29960784
std of return 3029.43510041
learning rate: 0.0110431526075
Epoch:  81  avg train loss: 0.105019234018  Reg Loss: 4.3736092415e-06 total time: 23.532825469970703
avg loss validation: 0.102620741063 failed count: 0
learning rate: 0.010976425999
Epoch:  82  avg train loss: 0.105841368578  Reg Loss: 4.36997399416e-06 total time: 49.74379801750183
avg loss validation: 0.119916180493 failed count: 1
learning rate: 0.0109108945118
Epoch:  83  avg train loss: 0.101401304084  Reg Loss: 4.36601104605e-06 total time: 74.05723333358765
avg loss validation: 0.0970173163233 failed count: 0
learning rate: 0.0108465228909
Epoch:  84  avg train loss: 0.102829338109  Reg Loss: 4.36105606041e-06 total time: 100.62617135047913
avg loss validation: 0.100895691415 failed count: 1
learning rate: 0.0107832773203
Epoch:  85  avg train loss: 0.101828133782  Reg Loss: 4.35745233117e-06 total time: 125.22677254676819
avg loss validation: 0.0943741391478 failed count: 0
iter 0
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 1
100/1000
iter 2
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 3
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
iter 4
100/1000
200/1000
300/1000
400/1000
iter 5
100/1000
200/1000
iter 6
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 7
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 9
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 11
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 12
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 14
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 15
100/1000
200/1000
iter 16
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 17
100/1000
200/1000
300/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 19
100/1000
200/1000
300/1000
400/1000
500/1000
returns [9043.4792318799718, 1404.5724323963711, 9401.6545335594583, 8278.497175889428, 3707.6112162247455, 2363.1554760545396, 9415.0539063763117, 9389.2213898661648, 9031.3852294778608, 8883.3155266044432, 9394.5488110292663, 8955.1953065460493, 9328.4487923246688, 9200.7124110313798, 9470.0047810303549, 2378.4806029737256, 5584.8986504129389, 3274.7084529588542, 9035.4783230557914, 4677.7704700343456]
mean return 7110.90963599
std of return 2888.70709731
learning rate: 0.0107211253484
Epoch:  86  avg train loss: 0.100023979343  Reg Loss: 4.31898682093e-06 total time: 25.014928102493286
avg loss validation: 0.0947446385234 failed count: 0
learning rate: 0.0106600358178
Epoch:  87  avg train loss: 0.0994111941594  Reg Loss: 4.31395789634e-06 total time: 52.83345627784729
avg loss validation: 0.0911608640896 failed count: 0
learning rate: 0.0105999788001
Epoch:  88  avg train loss: 0.0984150725754  Reg Loss: 4.30866428072e-06 total time: 80.98536705970764
avg loss validation: 0.0897328706638 failed count: 0
learning rate: 0.0105409255339
Epoch:  89  avg train loss: 0.0973637480388  Reg Loss: 4.30409112954e-06 total time: 109.10800004005432
avg loss validation: 0.0945846272284 failed count: 1
learning rate: 0.0104828483672
Epoch:  90  avg train loss: 0.0961636266198  Reg Loss: 4.29845659003e-06 total time: 135.1099672317505
avg loss validation: 0.11496022704 failed count: 2
iter 0
100/1000
200/1000
300/1000
400/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 2
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 3
100/1000
iter 4
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 5
100/1000
200/1000
300/1000
iter 6
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
iter 7
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 8
100/1000
200/1000
iter 9
100/1000
200/1000
300/1000
iter 10
100/1000
200/1000
iter 11
100/1000
iter 12
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 14
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 16
100/1000
iter 17
100/1000
200/1000
300/1000
400/1000
500/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 19
100/1000
200/1000
300/1000
returns [4016.8716615295257, 9751.7509039563574, 9408.8412204386095, 1381.6721204019898, 9631.0462060962182, 2933.1828928226832, 8991.2148047382125, 9498.4619928904103, 1975.0558670420482, 2886.1286279468036, 1931.7813443685018, 935.16786499858483, 7129.1842324534055, 9515.6642448371585, 9343.9418780910164, 5774.4271541763974, 860.52125085604257, 5450.3812864243009, 6879.0866185314917, 3327.8672852728869]
mean return 5581.11247289
std of return 3307.72734605
learning rate: 0.0104257207029
Epoch:  91  avg train loss: 0.0953791078042  Reg Loss: 4.31971418138e-06 total time: 26.18460249900818
avg loss validation: 0.092212610923 failed count: 0
learning rate: 0.0103695169473
Epoch:  92  avg train loss: 0.0959373322757  Reg Loss: 4.31470467815e-06 total time: 55.562607526779175
avg loss validation: 0.0944226847204 failed count: 1
learning rate: 0.0103142124626
Epoch:  93  avg train loss: 0.0940783641238  Reg Loss: 4.30914925471e-06 total time: 82.6777491569519
avg loss validation: 0.101041480672 failed count: 2
learning rate: 0.0102597835209
Epoch:  94  avg train loss: 0.0929084241177  Reg Loss: 4.30240988525e-06 total time: 109.78378915786743
avg loss validation: 0.0862406616454 failed count: 0
learning rate: 0.0102062072616
Epoch:  95  avg train loss: 0.0925333660179  Reg Loss: 4.29661831738e-06 total time: 138.73486018180847
avg loss validation: 0.0925868104986 failed count: 1
iter 0
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 2
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 3
100/1000
200/1000
iter 4
100/1000
200/1000
300/1000
iter 5
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 6
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 7
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 9
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 11
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 12
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 14
100/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 16
100/1000
200/1000
300/1000
400/1000
500/1000
iter 17
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 18
100/1000
200/1000
iter 19
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
returns [6356.7431143103395, 8862.8008639941927, 9614.0861227725491, 1974.0527429077897, 2701.1822687926951, 9650.8281099598444, 6336.8574630464518, 7142.6636213177608, 9789.741808079174, 9527.6990189988865, 8322.7335000231542, 8694.6677354849871, 7507.5745454448515, 9895.9010319496374, 1594.8533924462406, 9468.2448709883483, 5221.7483056998772, 7147.2381789636747, 2041.4873533032958, 7522.3946243269447]
mean return 6968.67493364
std of return 2763.27135359
learning rate: 0.0101534616513
Epoch:  96  avg train loss: 0.0907119008139  Reg Loss: 4.27702446625e-06 total time: 27.69031834602356
avg loss validation: 0.0945969679037 failed count: 0
learning rate: 0.0101015254455
Epoch:  97  avg train loss: 0.0911373993865  Reg Loss: 4.27031479463e-06 total time: 58.72263741493225
avg loss validation: 0.0893020658262 failed count: 0
learning rate: 0.0100503781526
Epoch:  98  avg train loss: 0.089848974943  Reg Loss: 4.26292865316e-06 total time: 89.307373046875
avg loss validation: 0.0937438946178 failed count: 1
learning rate: 0.01
Epoch:  99  avg train loss: 0.0878971593356  Reg Loss: 4.25523891056e-06 total time: 117.64688110351562
avg loss validation: 0.0949249181226 failed count: 2
learning rate: 0.0099503719021
Epoch:  100  avg train loss: 0.0890538026801  Reg Loss: 4.24893178318e-06 total time: 146.04734206199646
avg loss validation: 0.0947312250917 failed count: 3
iter 0
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 2
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 3
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 4
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 5
iter 6
100/1000
iter 7
100/1000
200/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 9
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
iter 11
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 12
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 14
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 16
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 17
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 19
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
returns [10146.457364622438, 9666.8985370693063, 9796.706473849843, 9865.8051187353067, 6294.5047601579545, 367.64120321310304, 1009.2507861212418, 2016.4209823276121, 9943.8394792270938, 9817.669201346378, 9671.5111841423113, 9946.0866126271812, 9839.5989704453132, 10012.24963401579, 6080.1178955988216, 9778.5331135872839, 9907.8575829407237, 9788.9714514986063, 10042.576106142256, 9898.3296828758102]
mean return 8194.55130703
std of return 3175.97043673
learning rate: 0.00990147542977
Epoch:  101  avg train loss: 0.0890228483506  Reg Loss: 4.19901197778e-06 total time: 29.30660843849182
avg loss validation: 0.0827694480689 failed count: 0
learning rate: 0.00985329278164
Epoch:  102  avg train loss: 0.0858468350893  Reg Loss: 4.19172120983e-06 total time: 61.378148555755615
avg loss validation: 0.0846533127873 failed count: 1
learning rate: 0.00980580675691
Epoch:  103  avg train loss: 0.0855564006406  Reg Loss: 4.18438420131e-06 total time: 91.7016978263855
avg loss validation: 0.0807506405868 failed count: 0
learning rate: 0.00975900072949
Epoch:  104  avg train loss: 0.0852983644001  Reg Loss: 4.17650581154e-06 total time: 124.32581758499146
avg loss validation: 0.0991745662735 failed count: 1
learning rate: 0.00971285862357
Epoch:  105  avg train loss: 0.0842644771443  Reg Loss: 4.16919263707e-06 total time: 154.70444178581238
avg loss validation: 0.0811113202803 failed count: 2
iter 0
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 2
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 3
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 4
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 5
100/1000
200/1000
300/1000
400/1000
500/1000
iter 6
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 7
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 9
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 11
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 12
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 14
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 15
100/1000
200/1000
iter 16
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 17
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 18
100/1000
200/1000
300/1000
400/1000
iter 19
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
returns [9643.5163351485844, 9741.8828384058852, 9680.0574081228096, 9797.5569957260141, 9502.6684297299616, 5347.4911267888974, 9780.1319191557504, 9867.2550915643933, 9658.6532668741038, 9729.5694592158034, 9598.3793514157878, 9494.0160111720397, 9607.2565281365387, 9574.179923994725, 9730.262980343954, 2435.4111721075533, 9576.6239937623468, 9753.8114689290414, 3702.9264735127308, 9666.954728421153]
mean return 8794.43027513
std of return 2138.5793968
learning rate: 0.00966736489046
Epoch:  106  avg train loss: 0.0832014712937  Reg Loss: 4.22527374121e-06 total time: 31.280072450637817
avg loss validation: 0.102717631685 failed count: 0
learning rate: 0.00962250448649
Epoch:  107  avg train loss: 0.0829223776555  Reg Loss: 4.21655929415e-06 total time: 65.73196625709534
avg loss validation: 0.0891533512793 failed count: 0
learning rate: 0.00957826285221
Epoch:  108  avg train loss: 0.0815265467233  Reg Loss: 4.20767195708e-06 total time: 99.76919865608215
avg loss validation: 0.0926150224069 failed count: 1
learning rate: 0.00953462589246
Epoch:  109  avg train loss: 0.0824423268382  Reg Loss: 4.19905984693e-06 total time: 131.92063403129578
avg loss validation: 0.0809528795903 failed count: 0
learning rate: 0.00949157995752
Epoch:  110  avg train loss: 0.0795008258047  Reg Loss: 4.19112140481e-06 total time: 165.86145877838135
avg loss validation: 0.0807053864043 failed count: 0
iter 0
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 2
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 3
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 4
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 5
100/1000
200/1000
300/1000
400/1000
iter 6
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 7
100/1000
200/1000
300/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 9
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 11
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 12
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 14
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 15
100/1000
iter 16
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 17
100/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 19
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
returns [9782.1828896824427, 6974.3885655978229, 9888.7719204549467, 9737.523356195692, 9572.0610575355386, 4195.6807188138264, 9891.7088567171613, 3044.4635579905744, 9518.6898349170988, 9709.2766740755451, 9708.2820145568057, 9772.6309404889289, 9720.6665863764974, 9621.4050401617769, 9680.5110627824597, 1442.3241191328443, 9447.7523493506833, 933.9742359690357, 9737.8302485263248, 9508.2903515672733]
mean return 8094.42071904
std of return 2964.29918669
learning rate: 0.00944911182523
Epoch:  111  avg train loss: 0.080167802327  Reg Loss: 4.14262121586e-06 total time: 32.742512941360474
avg loss validation: 0.0798699724569 failed count: 0
learning rate: 0.00940720868384
Epoch:  112  avg train loss: 0.0790854003903  Reg Loss: 4.13382514101e-06 total time: 68.44664716720581
avg loss validation: 0.0826686967839 failed count: 1
learning rate: 0.00936585811582
Epoch:  113  avg train loss: 0.0788323084813  Reg Loss: 4.12603277034e-06 total time: 103.38289022445679
avg loss validation: 0.073950231385 failed count: 0
learning rate: 0.0093250480824
Epoch:  114  avg train loss: 0.0777481547453  Reg Loss: 4.1175924021e-06 total time: 141.0216042995453
avg loss validation: 0.0872176816936 failed count: 1
learning rate: 0.00928476690885
Epoch:  115  avg train loss: 0.0768471382983  Reg Loss: 4.10857173629e-06 total time: 176.46367478370667
avg loss validation: 0.0877344198543 failed count: 2
iter 0
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 2
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 3
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 4
100/1000
iter 5
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 6
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 7
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 8
100/1000
200/1000
300/1000
400/1000
iter 9
100/1000
200/1000
300/1000
400/1000
500/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 11
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 12
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 14
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 16
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 17
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 19
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
returns [9211.9047710728337, 9268.994756946433, 9386.974227047036, 9440.0480062071147, 1091.0052767743293, 9191.0102758910234, 9426.3879013064779, 9651.1235583120961, 3880.0603476000151, 5377.116351323004, 9248.4994367571198, 9593.6785139675358, 9542.0219657036359, 9067.6577226415357, 9260.8368510737291, 9065.3864671965639, 9198.6018846879269, 9392.678655321708, 9317.2935549800095, 9287.3045595260101]
mean return 8444.92925422
std of return 2213.52481965
learning rate: 0.00924500327042
Epoch:  116  avg train loss: 0.0768306498628  Reg Loss: 4.10237693697e-06 total time: 35.67480945587158
avg loss validation: 0.0832219191487 failed count: 0
learning rate: 0.00920574617898
Epoch:  117  avg train loss: 0.0755623161571  Reg Loss: 4.09330418602e-06 total time: 73.25461220741272
avg loss validation: 0.0828341889989 failed count: 0
learning rate: 0.00916698497028
Epoch:  118  avg train loss: 0.0744605687815  Reg Loss: 4.08451674767e-06 total time: 111.19441604614258
avg loss validation: 0.0703306558842 failed count: 0
learning rate: 0.00912870929175
Epoch:  119  avg train loss: 0.0751344419937  Reg Loss: 4.07633353175e-06 total time: 148.85360956192017
avg loss validation: 0.0705793176721 failed count: 1
learning rate: 0.00909090909091
Epoch:  120  avg train loss: 0.0734921957783  Reg Loss: 4.06790500924e-06 total time: 185.83500909805298
avg loss validation: 0.0747381191572 failed count: 2
iter 0
100/1000
iter 1
100/1000
200/1000
iter 2
100/1000
200/1000
iter 3
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 4
100/1000
200/1000
300/1000
400/1000
iter 5
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 6
100/1000
200/1000
iter 7
100/1000
200/1000
300/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 9
100/1000
200/1000
iter 10
100/1000
iter 11
100/1000
200/1000
300/1000
iter 12
100/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
iter 14
100/1000
200/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 16
100/1000
200/1000
300/1000
iter 17
100/1000
200/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 19
100/1000
200/1000
returns [1457.7965311557912, 2095.7159530341796, 2297.0052430363789, 5762.1582591408669, 4560.0880210547894, 7133.9175929584544, 2453.5691167817813, 3197.1807102945982, 7174.8807722330321, 2566.1939830631168, 1539.4559003043275, 2774.5516123387597, 1431.8549593480734, 5313.5816267749879, 2534.0770359154121, 7211.6867889553605, 3371.6529572785298, 1757.3921999303384, 9886.2831615033429, 2148.8841086843736]
mean return 3833.39632669
std of return 2373.66725184
learning rate: 0.00905357460425
Epoch:  121  avg train loss: 0.0736160148118  Reg Loss: 4.06891570852e-06 total time: 35.47994351387024
avg loss validation: 0.0745921257461 failed count: 0
learning rate: 0.00901669634667
Epoch:  122  avg train loss: 0.0731977743123  Reg Loss: 4.06038822865e-06 total time: 74.24711847305298
avg loss validation: 0.0706896647984 failed count: 0
learning rate: 0.00898026510134
Epoch:  123  avg train loss: 0.0719137815194  Reg Loss: 4.05115518909e-06 total time: 113.61786890029907
avg loss validation: 0.0628666496489 failed count: 0
learning rate: 0.00894427191
Epoch:  124  avg train loss: 0.0715254932192  Reg Loss: 4.04264494285e-06 total time: 153.07253670692444
avg loss validation: 0.0715228578201 failed count: 1
learning rate: 0.00890870806375
Epoch:  125  avg train loss: 0.0719324026576  Reg Loss: 4.03385687959e-06 total time: 189.715327501297
avg loss validation: 0.064535780366 failed count: 2
iter 0
100/1000
200/1000
300/1000
400/1000
500/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 2
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 3
100/1000
200/1000
300/1000
400/1000
iter 4
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 5
100/1000
200/1000
300/1000
iter 6
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 7
100/1000
200/1000
300/1000
400/1000
iter 8
100/1000
200/1000
300/1000
400/1000
iter 9
100/1000
200/1000
300/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
iter 11
100/1000
200/1000
300/1000
400/1000
iter 12
100/1000
200/1000
300/1000
400/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
iter 14
100/1000
200/1000
300/1000
iter 15
100/1000
iter 16
100/1000
200/1000
300/1000
400/1000
500/1000
iter 17
100/1000
200/1000
300/1000
400/1000
500/1000
iter 18
100/1000
200/1000
300/1000
iter 19
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
returns [4833.9258806708658, 9833.2589453528708, 6309.2895027845543, 4180.8037170678117, 9971.4968683235402, 3448.7368485272809, 7009.8113903186604, 3619.5852390638643, 3758.8696417379488, 3361.2336491395545, 5406.2036504402495, 4031.3434268747205, 3678.9667145966932, 5573.1569887877231, 3572.4387712334292, 1288.1993926207367, 5059.7145337220227, 4844.3607128120293, 3201.5277833313939, 9448.5866954387238]
mean return 5121.57551764
std of return 2289.27141208
learning rate: 0.00887356509416
Epoch:  126  avg train loss: 0.0704031976531  Reg Loss: 4.00823052367e-06 total time: 36.49298715591431
avg loss validation: 0.06450076029 failed count: 0
learning rate: 0.00883883476483
Epoch:  127  avg train loss: 0.0705892594256  Reg Loss: 3.99942194667e-06 total time: 76.48449850082397
avg loss validation: 0.0757930108433 failed count: 1
learning rate: 0.00880450906326
Epoch:  128  avg train loss: 0.0701130676  Reg Loss: 3.99070082548e-06 total time: 114.18177771568298
avg loss validation: 0.0709716187783 failed count: 2
learning rate: 0.00877058019307
Epoch:  129  avg train loss: 0.0694007078295  Reg Loss: 3.98208665594e-06 total time: 151.9433934688568
avg loss validation: 0.0610907918682 failed count: 0
learning rate: 0.00873704056661
Epoch:  130  avg train loss: 0.0684334705839  Reg Loss: 3.97334067024e-06 total time: 191.82650876045227
avg loss validation: 0.0619207442966 failed count: 1
iter 0
100/1000
200/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 2
100/1000
200/1000
300/1000
iter 3
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 4
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 5
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 6
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 7
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 9
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 11
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 12
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 14
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 16
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 17
100/1000
200/1000
300/1000
400/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 19
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
returns [2532.2694503776147, 9619.0114802876888, 3496.3039233067216, 10063.068527943686, 9945.6123670037687, 9875.1412116774081, 9842.7771294874383, 9879.8927896024979, 6555.6363513987717, 10102.514098511143, 9886.496900982891, 9787.0220925083977, 9981.4229993843601, 9919.9300997913651, 9842.7799938037497, 9917.26067600643, 9923.4089754186698, 4242.8086102767375, 5918.0864517236378, 9740.6522087335197]
mean return 8553.60481691
std of return 2431.89036888
learning rate: 0.00870388279778
Epoch:  131  avg train loss: 0.0685455758035  Reg Loss: 3.97470088084e-06 total time: 37.97544264793396
avg loss validation: 0.0746583691352 failed count: 0
learning rate: 0.00867109969524
Epoch:  132  avg train loss: 0.0674133274796  Reg Loss: 3.96581090108e-06 total time: 79.34194707870483
avg loss validation: 0.0672031001841 failed count: 0
learning rate: 0.00863868425581
Epoch:  133  avg train loss: 0.0660210982443  Reg Loss: 3.95654192078e-06 total time: 120.2657859325409
avg loss validation: 0.0805612968625 failed count: 1
learning rate: 0.00860662965824
Epoch:  134  avg train loss: 0.0668469950125  Reg Loss: 3.94729261048e-06 total time: 159.59495425224304
avg loss validation: 0.0666004332823 failed count: 0
learning rate: 0.00857492925713
Epoch:  135  avg train loss: 0.0662947690633  Reg Loss: 3.93884209038e-06 total time: 201.03990077972412
avg loss validation: 0.0643108947323 failed count: 0
iter 0
100/1000
200/1000
300/1000
400/1000
iter 1
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
iter 2
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 3
100/1000
200/1000
iter 4
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 5
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 6
100/1000
200/1000
300/1000
400/1000
500/1000
iter 7
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 8
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 9
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 10
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 11
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 12
100/1000
200/1000
iter 13
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
iter 14
100/1000
200/1000
iter 15
100/1000
200/1000
300/1000
400/1000
500/1000
iter 16
100/1000
200/1000
300/1000
iter 17
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
900/1000
1000/1000
iter 18
100/1000
200/1000
300/1000
400/1000
500/1000
600/1000
700/1000
800/1000
iter 19
100/1000
200/1000
300/1000
400/1000
returns [4285.4446303415989, 7743.7872841109465, 10137.415093558719, 1798.2721521356998, 10181.571918540058, 10387.552089681774, 5658.1070835044538, 10311.039651590227, 10062.502781305049, 10340.115166736918, 10239.735949695883, 5997.7645987152737, 2423.7951513550584, 6815.1291102384712, 2530.2975660955526, 5687.5206857731719, 3200.3446916919252, 10166.934580929226, 8269.0231734919398, 4680.9334534419258]
mean return 7045.86434065
std of return 3043.93287347
learning rate: 0.00854357657717
Epoch:  136  avg train loss: 0.0652443641114  Reg Loss: 3.9267435268e-06 total time: 40.082913637161255
avg loss validation: 0.0659301636259 failed count: 0
learning rate: 0.00851256530759
