3.6.0 |Anaconda custom (64-bit)| (default, Dec 23 2016, 12:22:00) 
[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]
loading and building expert policy
obs (1, 376) (1, 376)
loaded and built
iter 0
100/1000
iter 1
100/1000
iter 2
100/1000
iter 3
100/1000
iter 4
100/1000
iter 5
iter 6
100/1000
iter 7
100/1000
iter 8
iter 9
100/1000
iter 10
100/1000
iter 11
100/1000
iter 12
100/1000
iter 13
100/1000
iter 14
iter 15
100/1000
iter 16
iter 17
100/1000
iter 18
100/1000
iter 19
100/1000
returns [1014.1706398611702, 952.79525633608569, 715.42276315698211, 1315.750118234406, 806.0039544173701, 442.02092260194132, 631.0921479888724, 738.84133089153988, 554.97871571454527, 938.70080919471252, 755.61824255970839, 1045.6743348229948, 771.38467548841504, 669.67293163395561, 605.57141733120307, 638.92699871994853, 624.99084437037629, 621.1332597143645, 709.02833627560165, 792.9688232079825]
mean return 767.237326126
std of return 196.907482113
learning rate: 0.0707106781187
Epoch:  1  avg train loss: 12.891418185  Reg Loss: 2.04256784043e-06 total time: 0.8788776397705078
avg loss validation: 0.820945695145 failed count: 0
learning rate: 0.057735026919
Epoch:  2  avg train loss: 0.601888519785  Reg Loss: 2.37648900007e-06 total time: 2.4053730964660645
avg loss validation: 0.512396913972 failed count: 0
learning rate: 0.05
Epoch:  3  avg train loss: 0.468578636651  Reg Loss: 2.37434670518e-06 total time: 3.9227399826049805
avg loss validation: 0.453787719032 failed count: 0
learning rate: 0.04472135955
Epoch:  4  avg train loss: 0.424725680779  Reg Loss: 2.37152366574e-06 total time: 5.437060356140137
avg loss validation: 0.42226843382 failed count: 0
learning rate: 0.0408248290464
Epoch:  5  avg train loss: 0.399632345076  Reg Loss: 2.36899762816e-06 total time: 6.949052333831787
avg loss validation: 0.400731558085 failed count: 0
learning rate: 0.0377964473009
Epoch:  6  avg train loss: 0.381951076262  Reg Loss: 2.36706944813e-06 total time: 8.478679656982422
avg loss validation: 0.385576280283 failed count: 0
learning rate: 0.0353553390593
Epoch:  7  avg train loss: 0.368960827794  Reg Loss: 2.3652421594e-06 total time: 9.987210750579834
avg loss validation: 0.373488842121 failed count: 0
learning rate: 0.0333333333333
Epoch:  8  avg train loss: 0.358656963421  Reg Loss: 2.3640288155e-06 total time: 11.500231504440308
avg loss validation: 0.365077890583 failed count: 0
learning rate: 0.0316227766017
Epoch:  9  avg train loss: 0.350412859401  Reg Loss: 2.36276398837e-06 total time: 13.009625673294067
avg loss validation: 0.357416387692 failed count: 0
learning rate: 0.0301511344578
Epoch:  10  avg train loss: 0.343388485396  Reg Loss: 2.36179721056e-06 total time: 14.523906230926514
avg loss validation: 0.351419046289 failed count: 0
iter 0
100/1000
iter 1
iter 2
iter 3
iter 4
iter 5
100/1000
iter 6
iter 7
iter 8
iter 9
iter 10
iter 11
iter 12
100/1000
iter 13
iter 14
iter 15
iter 16
iter 17
iter 18
iter 19
returns [766.60318909462671, 456.26403511606151, 506.35215958618073, 562.91577115969505, 615.49814716212791, 657.26690035679701, 410.59680756851952, 520.34653732254435, 500.06007275153428, 437.34563945996672, 478.28306611657825, 606.02400434270828, 649.68297805081227, 379.03455778812048, 554.2487743179762, 280.43230513864933, 474.04133641281868, 572.63589108162546, 600.46551614186376, 610.15207914547341]
mean return 531.912488406
std of return 108.421805952
learning rate: 0.0288675134595
Epoch:  11  avg train loss: 0.345965144579  Reg Loss: 2.28536990419e-06 total time: 0.8471980094909668
avg loss validation: 0.345368467028 failed count: 0
learning rate: 0.0277350098113
Epoch:  12  avg train loss: 0.340455743832  Reg Loss: 2.28464691963e-06 total time: 2.3891875743865967
avg loss validation: 0.34097159999 failed count: 0
learning rate: 0.0267261241912
Epoch:  13  avg train loss: 0.335718699483  Reg Loss: 2.2840362922e-06 total time: 3.93483304977417
avg loss validation: 0.337019672066 failed count: 0
learning rate: 0.0258198889747
Epoch:  14  avg train loss: 0.331459482873  Reg Loss: 2.28348895055e-06 total time: 5.540601491928101
avg loss validation: 0.333312465588 failed count: 0
learning rate: 0.025
Epoch:  15  avg train loss: 0.327663808798  Reg Loss: 2.28301491939e-06 total time: 7.151282548904419
avg loss validation: 0.329941448494 failed count: 0
learning rate: 0.0242535625036
Epoch:  16  avg train loss: 0.324152342242  Reg Loss: 2.2826291784e-06 total time: 8.759094953536987
avg loss validation: 0.32679314372 failed count: 0
learning rate: 0.0235702260396
Epoch:  17  avg train loss: 0.320885082106  Reg Loss: 2.28226302769e-06 total time: 10.367446422576904
avg loss validation: 0.323869767801 failed count: 0
learning rate: 0.0229415733871
Epoch:  18  avg train loss: 0.317891111462  Reg Loss: 2.28206163428e-06 total time: 11.89631199836731
avg loss validation: 0.320852660543 failed count: 0
learning rate: 0.022360679775
Epoch:  19  avg train loss: 0.315003997092  Reg Loss: 2.28190146845e-06 total time: 13.439714908599854
avg loss validation: 0.318367467429 failed count: 0
learning rate: 0.0218217890236
Epoch:  20  avg train loss: 0.31246058573  Reg Loss: 2.28174218266e-06 total time: 14.985357999801636
avg loss validation: 0.316439702552 failed count: 0
iter 0
iter 1
100/1000
iter 2
iter 3
iter 4
iter 5
iter 6
iter 7
100/1000
iter 8
iter 9
iter 10
iter 11
iter 12
iter 13
iter 14
iter 15
iter 16
iter 17
iter 18
100/1000
iter 19
returns [608.78845987599198, 673.62785046038312, 501.57467914098112, 425.59578031810946, 345.20278850060402, 388.09256233156862, 543.20123362161701, 652.68320925458397, 366.20597281789316, 452.47070307971865, 631.19346131480177, 302.46037625643686, 469.19219850197959, 600.51565124358615, 656.05269084877648, 358.33818415837743, 553.90137347909081, 600.70804376483215, 815.89833509478626, 428.1761455752445]
mean return 518.693984982
std of return 132.676130156
learning rate: 0.0213200716356
Epoch:  21  avg train loss: 0.314716721369  Reg Loss: 2.41411581283e-06 total time: 0.863410472869873
avg loss validation: 0.309711599308 failed count: 0
learning rate: 0.0208514414057
Epoch:  22  avg train loss: 0.311957904066  Reg Loss: 2.4139632675e-06 total time: 2.4176385402679443
avg loss validation: 0.307601434332 failed count: 0
learning rate: 0.0204124145232
Epoch:  23  avg train loss: 0.309515445352  Reg Loss: 2.41389479745e-06 total time: 3.9843320846557617
avg loss validation: 0.305554993968 failed count: 0
learning rate: 0.02
Epoch:  24  avg train loss: 0.307197021287  Reg Loss: 2.41385061664e-06 total time: 5.536658048629761
avg loss validation: 0.303395689065 failed count: 0
learning rate: 0.0196116135138
Epoch:  25  avg train loss: 0.304936143986  Reg Loss: 2.41382731084e-06 total time: 7.09211277961731
avg loss validation: 0.301692001126 failed count: 0
learning rate: 0.019245008973
Epoch:  26  avg train loss: 0.302817691531  Reg Loss: 2.41393298481e-06 total time: 8.639665126800537
avg loss validation: 0.299559508465 failed count: 0
learning rate: 0.0188982236505
Epoch:  27  avg train loss: 0.300760577079  Reg Loss: 2.41406793946e-06 total time: 10.187102317810059
avg loss validation: 0.297767662947 failed count: 0
learning rate: 0.0185695338177
Epoch:  28  avg train loss: 0.298884379634  Reg Loss: 2.41418686211e-06 total time: 11.744004726409912
avg loss validation: 0.296112335068 failed count: 0
learning rate: 0.0182574185835
Epoch:  29  avg train loss: 0.296981201748  Reg Loss: 2.41433499121e-06 total time: 13.406432390213013
avg loss validation: 0.294301698897 failed count: 0
learning rate: 0.0179605302027
Epoch:  30  avg train loss: 0.295188753552  Reg Loss: 2.41448250799e-06 total time: 15.082400798797607
avg loss validation: 0.292756046427 failed count: 0
iter 0
iter 1
100/1000
iter 2
100/1000
iter 3
100/1000
iter 4
100/1000
iter 5
iter 6
100/1000
iter 7
100/1000
iter 8
iter 9
iter 10
iter 11
100/1000
iter 12
100/1000
iter 13
iter 14
100/1000
iter 15
100/1000
iter 16
100/1000
iter 17
iter 18
100/1000
iter 19
returns [614.91819908302909, 1000.7520930736356, 868.53841097190127, 683.45854275348722, 634.90675836243702, 630.21467580015656, 1025.6133947197332, 801.12338858574242, 607.90056895958003, 585.19148775303188, 479.20577831555829, 862.76566293272253, 643.91044387280226, 321.46797342477959, 843.30703524298531, 853.90051414914387, 969.94151329982833, 378.05470918991125, 650.85115094829314, 596.25499189311506]
mean return 702.613864667
std of return 190.898760147
learning rate: 0.0176776695297
Epoch:  31  avg train loss: 0.302778729251  Reg Loss: 2.32411926211e-06 total time: 0.8936436176300049
avg loss validation: 0.297842984358 failed count: 0
learning rate: 0.0174077655956
Epoch:  32  avg train loss: 0.300807886104  Reg Loss: 2.3244805829e-06 total time: 2.481673002243042
avg loss validation: 0.296871967078 failed count: 0
learning rate: 0.0171498585143
Epoch:  33  avg train loss: 0.299045240847  Reg Loss: 2.32486279859e-06 total time: 4.067381381988525
avg loss validation: 0.295731448169 failed count: 0
learning rate: 0.0169030850946
Epoch:  34  avg train loss: 0.297368917888  Reg Loss: 2.32523544192e-06 total time: 5.7401814460754395
avg loss validation: 0.294667684526 failed count: 0
learning rate: 0.0166666666667
Epoch:  35  avg train loss: 0.295863346405  Reg Loss: 2.32566521579e-06 total time: 7.495730876922607
avg loss validation: 0.293475857355 failed count: 0
learning rate: 0.0164398987305
Epoch:  36  avg train loss: 0.29433501689  Reg Loss: 2.32617833704e-06 total time: 9.260754346847534
avg loss validation: 0.292321671811 failed count: 0
learning rate: 0.0162221421131
Epoch:  37  avg train loss: 0.292894012503  Reg Loss: 2.32666315198e-06 total time: 10.895938873291016
avg loss validation: 0.291286101704 failed count: 0
learning rate: 0.0160128153805
Epoch:  38  avg train loss: 0.291503174736  Reg Loss: 2.3272317429e-06 total time: 12.779019832611084
avg loss validation: 0.290201039154 failed count: 0
learning rate: 0.0158113883008
Epoch:  39  avg train loss: 0.290130598608  Reg Loss: 2.32780278049e-06 total time: 14.594160795211792
avg loss validation: 0.289040606318 failed count: 0
learning rate: 0.0156173761889
Epoch:  40  avg train loss: 0.288829829969  Reg Loss: 2.32837705054e-06 total time: 16.367380142211914
avg loss validation: 0.287898983768 failed count: 0
iter 0
100/1000
iter 1
100/1000
iter 2
100/1000
iter 3
iter 4
100/1000
iter 5
100/1000
iter 6
100/1000
iter 7
100/1000
iter 8
iter 9
100/1000
iter 10
100/1000
iter 11
100/1000
iter 12
100/1000
iter 13
100/1000
iter 14
100/1000
iter 15
100/1000
iter 16
iter 17
100/1000
iter 18
100/1000
iter 19
100/1000
returns [836.60907257213057, 1040.0385151181054, 659.64830229191227, 620.9288547855914, 687.5849184758606, 663.31872316585543, 1062.2122533446095, 973.65470199897413, 397.56708867202195, 801.68038402100217, 723.95192151585911, 735.26917468540091, 831.43626484456252, 706.88086886175188, 792.46377782265722, 861.54718768785324, 509.3388074694725, 889.32229298557183, 818.85786169034293, 1434.7269352723367]
mean return 802.351895364
std of return 214.705883522
learning rate: 0.0154303349962
Epoch:  41  avg train loss: 0.298836939805  Reg Loss: 2.42144637261e-06 total time: 0.9288642406463623
avg loss validation: 0.296014133576 failed count: 0
learning rate: 0.0152498570333
Epoch:  42  avg train loss: 0.296912933613  Reg Loss: 2.42227418823e-06 total time: 2.5652365684509277
avg loss validation: 0.294446972288 failed count: 0
learning rate: 0.0150755672289
Epoch:  43  avg train loss: 0.295461250517  Reg Loss: 2.42300878076e-06 total time: 4.416164875030518
avg loss validation: 0.293724911191 failed count: 0
learning rate: 0.01490711985
Epoch:  44  avg train loss: 0.293931686941  Reg Loss: 2.42388921542e-06 total time: 5.842272996902466
avg loss validation: 0.29243565359 failed count: 0
learning rate: 0.0147441956155
Epoch:  45  avg train loss: 0.292544866707  Reg Loss: 2.42477768862e-06 total time: 7.543516159057617
avg loss validation: 0.291317404332 failed count: 0
learning rate: 0.0145864991498
Epoch:  46  avg train loss: 0.291160826022  Reg Loss: 2.42585685868e-06 total time: 9.245688915252686
avg loss validation: 0.290108568312 failed count: 0
learning rate: 0.0144337567297
Epoch:  47  avg train loss: 0.289844277629  Reg Loss: 2.42680175593e-06 total time: 10.950209617614746
avg loss validation: 0.289068881077 failed count: 0
learning rate: 0.0142857142857
Epoch:  48  avg train loss: 0.288600728076  Reg Loss: 2.42789936836e-06 total time: 12.573031663894653
avg loss validation: 0.287845421996 failed count: 0
learning rate: 0.0141421356237
Epoch:  49  avg train loss: 0.287412147087  Reg Loss: 2.42894700127e-06 total time: 14.195671558380127
avg loss validation: 0.286946555516 failed count: 0
learning rate: 0.0140028008403
Epoch:  50  avg train loss: 0.286199889404  Reg Loss: 2.43003349e-06 total time: 15.831099510192871
avg loss validation: 0.28587598086 failed count: 0
iter 0
100/1000
iter 1
100/1000
iter 2
100/1000
iter 3
100/1000
iter 4
100/1000
iter 5
iter 6
100/1000
iter 7
100/1000
iter 8
100/1000
iter 9
100/1000
iter 10
100/1000
iter 11
100/1000
iter 12
100/1000
iter 13
iter 14
iter 15
100/1000
iter 16
iter 17
100/1000
iter 18
100/1000
iter 19
100/1000
returns [806.15451536162084, 854.16892592577108, 690.68868030850922, 852.28960586275525, 1128.2866181534578, 511.14693147928369, 676.90109488745213, 695.71701313788947, 788.70153080013824, 1382.4002078225553, 891.50907180540742, 1158.3357943455744, 788.38146391488306, 556.36643429547348, 633.45192446447265, 784.79850662939316, 561.90186712197419, 926.59426560035149, 814.93341281687299, 636.57983853396945]
mean return 806.965385163
std of return 211.79296644
learning rate: 0.0138675049056
Epoch:  51  avg train loss: 0.293529689731  Reg Loss: 2.335723885e-06 total time: 1.0487453937530518
avg loss validation: 0.291002032674 failed count: 0
learning rate: 0.0137360563949
Epoch:  52  avg train loss: 0.292130154692  Reg Loss: 2.33686905146e-06 total time: 2.7230641841888428
avg loss validation: 0.289769548829 failed count: 0
learning rate: 0.0136082763488
Epoch:  53  avg train loss: 0.29079944065  Reg Loss: 2.33785399145e-06 total time: 4.60504674911499
avg loss validation: 0.288813597503 failed count: 0
learning rate: 0.0134839972493
Epoch:  54  avg train loss: 0.28961414147  Reg Loss: 2.33907785497e-06 total time: 6.0645201206207275
avg loss validation: 0.287749859125 failed count: 0
learning rate: 0.0133630620956
Epoch:  55  avg train loss: 0.28841391358  Reg Loss: 2.34029012553e-06 total time: 7.729088306427002
avg loss validation: 0.286923653011 failed count: 0
learning rate: 0.0132453235707
Epoch:  56  avg train loss: 0.287258777602  Reg Loss: 2.34136522379e-06 total time: 9.394520044326782
avg loss validation: 0.28617619507 failed count: 0
learning rate: 0.013130643286
Epoch:  57  avg train loss: 0.286125231665  Reg Loss: 2.34251687835e-06 total time: 11.188835620880127
